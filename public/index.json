[{"authors":["Ted"],"categories":null,"content":"Ted Laderas is an Assistant Professor in the Division of Bioinformatics and Computational Biology in the Department of Medical Informatics and Clinical Epidemiology. He is a certified RStudio Instructor in both the Tidyverse and Shiny. He is also a co-founder of the Cascadia R conference and BioData Club.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"b51ada7fb0c28b09305ee455b1e73af6","permalink":"https://sph-r-programming-2023.netlify.app/authors/jessica/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jessica/","section":"authors","summary":"Ted Laderas is an Assistant Professor in the Division of Bioinformatics and Computational Biology in the Department of Medical Informatics and Clinical Epidemiology. He is a certified RStudio Instructor in both the Tidyverse and Shiny. He is also a co-founder of the Cascadia R conference and BioData Club.","tags":null,"title":"Ted Laderas","type":"authors"},{"authors":["Jessica"],"categories":null,"content":"Jessica Minnier is an Associate Professor in the OHSU-PSU School of Public Health and the Knight Cancer Institute Biostatistics Shared Resource.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"c6de7d38fbd44ef0c4e79b5f2459a01e","permalink":"https://sph-r-programming-2023.netlify.app/authors/ted/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ted/","section":"authors","summary":"Jessica Minnier is an Associate Professor in the OHSU-PSU School of Public Health and the Knight Cancer Institute Biostatistics Shared Resource.","tags":null,"title":"Jessica Minnier","type":"authors"},{"authors":null,"categories":null,"content":" Preparation Problem sets Evaluation assignments Code-through Exams Final project Preparation You will get the most out of this class if you (1) attend class, (2) complete all the readings, and (3) engage1 with the readings.2\nTo encourage attendance and preparation, I use an honor-system-based self-reporting system. At the beginning of every class, I will post a quiz on iCollege with the following questions:\nAre you here in class today? Yes (3.5 points) No (0 points) How much of today’s reading did you finish? 100% (6 points) 75–99% (5 points) 50–74% (4 points) 11–49% (2 points) 0–10% (0 points) How well did you read? I was engaged and read carefully (6 points) I was fairly engaged and read fairly carefully (4 points) I skimmed it (2 points) I didn’t read it at all (0 points) Each day is worth 15.5 points. It is unlikely that you’ll score a 15.5 every day.3 Your total preparation score will naturally shift up at the end of the semester, though, since the preparation category is worth 210 points rather than 217 (15.5 × 14), so be honest—there’s wiggle room in the point system for honesty.\nProblem sets To practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nThere are 7 problem sets on the schedule. I will keep the highest grades for 6 of them. That is, I will drop the lowest score (even if it’s a zero). This means you can skip one of the problem sets. You need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n✔+: (44 points (110%) in gradebook) Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often. ✔: (37 points (93%) in gradebook) Problem set is 70–99% complete and most answers are correct. This is the expected level of performance. ✔−: (20 points (50%) in gradebook) Problem set is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often. You may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment.\nEvaluation assignments For your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using the same check system from the problem sets, but scaled down to 30 points.\nCode-through The objectives of this class include “Become curious and confident in consuming and producing evaluations,” “Run statistical models,” and “Share your analyses and data with the public.” To help you with this, you will write a code-through tutorial of some program evaluation principle or approach.\nOne of the reasons R is so popular is because the R community is exceptionally generous and open and sharing.4 The internet is full of tutorials and code-throughs where people explain how to do something interesting with R.\nYou will write one code-through or tutorial during the semester on a of your choice (related to program evaluation and causal inference, of course). You will complete this on your own, but you can get help from your team (but you can’t all write about the same topic). You can find the instructions for the assignment here.\nThis assignment will be graded using the same check system from the problem sets, but scaled down to 30 points.\nExams There will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will be timed, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them.5\nFinal project At the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam.\nTake detailed notes, work through the example code and try to understand it, have vivid dreams about statistics, etc.↩︎\nAlso (4) ask for help!↩︎\nBut it would be amazing if you did!↩︎\nSo are Python and other modern open source languages too.↩︎\nAgain, be honest.↩︎\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"https://sph-r-programming-2023.netlify.app/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"Preparation Problem sets Evaluation assignments Code-through Exams Final project Preparation You will get the most out of this class if you (1) attend class, (2) complete all the readings, and (3) engage1 with the readings.2\nTo encourage attendance and preparation, I use an honor-system-based self-reporting system. At the beginning of every class, I will post a quiz on iCollege with the following questions:\nAre you here in class today? Yes (3.","tags":null,"title":"Assignment details","type":"docs"},{"authors":null,"categories":null,"content":" You can download a BibTeX file of all the non-web-based readings in the course:\nreferences.bib You can open the file in BibDesk on macOS, JabRef on Windows, or Zotero or Mendeley online.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"5912f73d0134416d302ef6bce989b8bf","permalink":"https://sph-r-programming-2023.netlify.app/reference/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reference/","section":"reference","summary":"You can download a BibTeX file of all the non-web-based readings in the course:\nreferences.bib You can open the file in BibDesk on macOS, JabRef on Windows, or Zotero or Mendeley online.","tags":null,"title":"Citations and bibliography","type":"docs"},{"authors":null,"categories":null,"content":" I will post all the materials (slides, example code, in-class activities, etc.) from each class session on the day of class.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"108da05078d325a5a1f01a1ff2583053","permalink":"https://sph-r-programming-2023.netlify.app/class/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/","section":"class","summary":"I will post all the materials (slides, example code, in-class activities, etc.) from each class session on the day of class.","tags":null,"title":"Class details","type":"docs"},{"authors":null,"categories":null,"content":" Function of the week posts are here.\nSee 2021 functions of the week here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"8f52ff357673739ae8d6b752832ba727","permalink":"https://sph-r-programming-2023.netlify.app/functions/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/","section":"functions","summary":"Function of the week posts are here.\nSee 2021 functions of the week here.","tags":null,"title":"Function of the Week","type":"docs"},{"authors":null,"categories":null,"content":" Completing the readings after each class is an essential part of this course, if you want to keep learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672873994,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"https://sph-r-programming-2023.netlify.app/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"Completing the readings after each class is an essential part of this course, if you want to keep learning.","tags":null,"title":"Reading policy","type":"docs"},{"authors":null,"categories":null,"content":" Install R/Rstudio Class files R Project files Slides This year’s class video Last Year’s Class Video Post-Class Pacing Muddiest Points Clearest Points Other messages, just a selection Additional Info Projects in RStudio Desktop Slack Intro Install R/Rstudio Before class, please install R and Rstudio. If it has been a while since you installed R, please re-install R to update to the most recent version (warning: you may lose all your installed packages and will have to re-install them).\nInstallation instructions can be found here.\nPlease also download the “part1” folder in this course materials link. Unzip the folder if needed. Open the Rstudio project by double clicking on the .Rproj file (“Rstudio project file”). Run the 00-install-packages.R script to install necessary packages. A video on how to do this can be found here.\nClass files R Project files Before each class, I will update this folder link with the appropriate “part” folder. Please download the part1 folder. Unzip this folder and open in Rstudio by double clicking on the .Rproj file. This folder will have the files for this part and the assignment.\nSlides Open the class introduction slides in a separate window: https://sph-r-programming-2023.netlify.app/01-introduction_slides#1\nThis year’s class video See Slack for the zoom recording link\nLast Year’s Class Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\nThank you to everyone who responded to the survey the first week!\nPacing Mean 3.18, IQR [3,3] so, that’s a good sign, though there was one comment it went a little fast. I admittedly was trying to cram in a lot of basics all at once, so I’ll try to go a touch slower with the hard things.\nMuddiest Points Remember, all of this is anonymous. I don’t post everything everyone says on here, but I do read them all and think about how to improve the class based on what everyone says.\nBoolean data, until you explained it\nWe will talk more about boolean data in class 2, I kind of rushed the intro to that but we’ll definitely see more examples!\ndefault arguments\nI added this one, I want to make sure to show you the help in R and how we know what the “default” arguments are, that we don’t need to specify.\nremoving missing values\nYes this is a confusing thing in R, one point to remember is the difference between a function like na.omit() and an argument like na.rm = TRUE which sets the missing data behavior within a specific function like mean().\nmyvec \u0026lt;- c(1, NA, 3) # removes missing values, does not save your work! na.omit(myvec) ## [1] 1 3 ## attr(,\u0026quot;na.action\u0026quot;) ## [1] 2 ## attr(,\u0026quot;class\u0026quot;) ## [1] \u0026quot;omit\u0026quot; # removes missing values, overwrites the object/variable myvec after removing them myvec \u0026lt;- na.omit(myvec) myvec \u0026lt;- c(1, NA, 3) # default behavior is to include NA in the computation mean(myvec) ## [1] NA # specifies that we want to get rid of NA first mean(myvec, na.rm = TRUE) ## [1] 2 # different functions have different arguments to handle missing data # see ?cor for help and the explanation of the use argument vec1 \u0026lt;- c(1, NA, 2, 3) vec2 \u0026lt;- c(2, 3, NA, 4) cor(vec1, vec2) ## [1] NA cor(vec1, vec2, use = \u0026quot;pairwise.complete.obs\u0026quot;) ## [1] 1 # cor(vec1, vec2, use = \u0026quot;all.obs\u0026quot;) # this throws an error, why? Data types and vectors. It was clear, however, when I watched the class recording.\nWe will go over this again in class 2 when we talk about data!\nWhile I was reading the materials about vectors and variables, I’m still not very clear on the differences between vectors and variables. For instance, when we concatenate a list of regions (example from book) and create a vector named “region.” It sounds similar to how we assign values or characters to create a variable\nThis is a great point, and I tend to be a little lax with the definitions of some of these terms so apologies if it is confusing.\nI would say a variable is the same as an object in R. It is the name of something that we save and that we can see in our environment tab. That means it could be a vector, a data set, a list, a unique object type – all data types we will talk about in the coming classes.\nI also use the word “variable” when talking about columns of a data set or data frame, though. Therefore, it’s not a precise word and I’m sorry I use it so much!\nA vector is a specific type of object in R. It has a length and a class/type. It does not have a “width” like a data frame does (we will talk about these in class 2). We will also talk about types or classes of vectors (character, numeric, boolean) a bit more in these classes.\nFor a more thorough introduction, read R for Data Science Vector. If you want a rather advanced treatment of data types, see Advanced R.\nAs far as naming vectors or data, we often call them something that we can easily remember or make sense of. I think that also can cause confusion though, in the regions example.\nThis all make more sense once we talk about data frames, which contain vectors as columns!\npackages - why did my R crash?\nUgh I’m so sorry and I don’t have a clear idea. My best guess is that there were older packages installed and for some reason pacman::p_load tried to install packages without installing their dependencies first packages that the installed package relies on to work, and often need at least a certain version. Perhaps if you don’t update your packages all that often, install.packages() is the safer option?\nThe options for code blocks in r markdown\nI didn’t talk about this much yet, but I will keep showing examples of this. In the meantime, here are some good references, that I often have to go back to because I forget most of them most of the time:\nChunk options long list\nR markdown book, chunk options chapter\nI will also try to mention global options in class 2 as well.\nhow to also have an output below my code chuck as well\nI’ll talk about this again/more as well. This is a YAML option, and can be set using the “gear” icon next to the “Knit” button at the top of an Rmd (Chunk Output Inline vs Chunk Output Console). I think we can’t have it both ways. Also note that table output will look different from interactive R markdown and knitted R markdown sometimes. That can be a point of confusion. You can also change how that looks in “Output Options” from that gear dropdown menu (General -\u0026gt; print data frames as:)\nR markdown in general, also R studio projects\nUnderstandable, I threw a lot of new stuff at most of you, and I’ll focus more on these things in class 2! I haven’t shown you the full benefits of using Rstudio projects yet because we haven’t started working with data. But hopefully class 2 and 3 it will become a bit more clear.\nClearest Points Lots of things here I’m not including, but, thank you for all of it!\nConcatenate! I have never known what c() stood for!\nIt’s a weird one, for sure!\nFirst time real exposure to R, so I REALLY was amazed by knitting the Rmd and how the class content was all “interactively” set in the Rmd.\nIt’s one of the main reasons why I just start using Rmd right away, because it’s pretty neat. It might cause more headaches later because it takes time getting used to, but it’s worth it to me.\nOther messages, just a selection Lots of you liked having challenges. Sometimes I get carried away adding too much instruction because there is so much I want to show you, so I hope I provide enough time for challenges this year.\ni’ve had R experience but it’s difficult for me to quickly learn and adapt to it. I understand how to use it but have difficulty creating things like tables or organizing data. I’m hoping by the end of this course, i’ll be able to gain more knowledge to allow me to do those types of task.\nYou are my perfect audience, these are my goals, too!\nAfter 2 years of just sort of flinging myself at R willy-nilly, the first class showed me a lot of tips for using R that have already made my life easier.\nSo happy to hear it!\nAdditional Info Projects in RStudio Desktop See this short video about creating projects in Rstudio desktop if it’s a new concept to you:\nSlack Intro Slack invite link is on Sakai, and will be emailed before class.\n","date":1673395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673999204,"objectID":"ac47977a15b3902ca3402f61e5bf9df2","permalink":"https://sph-r-programming-2023.netlify.app/class/01-class/","publishdate":"2023-01-11T00:00:00Z","relpermalink":"/class/01-class/","section":"class","summary":"Install R/Rstudio Class files R Project files Slides This year’s class video Last Year’s Class Video Post-Class Pacing Muddiest Points Clearest Points Other messages, just a selection Additional Info Projects in RStudio Desktop Slack Intro Install R/Rstudio Before class, please install R and Rstudio. If it has been a while since you installed R, please re-install R to update to the most recent version (warning: you may lose all your installed packages and will have to re-install them).","tags":null,"title":"Class 1: Introduction to R/Rstudio/Vectors","type":"docs"},{"authors":null,"categories":null,"content":" Instructions Rubric (10 points) Instructions Please finish the assignment in the notebook and submit in the Submissions tab in Sakai.\nRubric (10 points) Did the student load the images? (3 points) Did the Student generate histograms? (2 points) Did the student comment on the histograms and the images? (5 points) ","date":1585267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"267d3eeb134ec40c34f76f19395cc74b","permalink":"https://sph-r-programming-2023.netlify.app/assignment/01-problem-set/","publishdate":"2020-03-27T00:00:00Z","relpermalink":"/assignment/01-problem-set/","section":"assignment","summary":" Instructions Rubric (10 points) Instructions Please finish the assignment in the notebook and submit in the Submissions tab in Sakai.\nRubric (10 points) Did the student load the images? (3 points) Did the Student generate histograms? (2 points) Did the student comment on the histograms and the images? (5 points) ","tags":null,"title":"Problem set 1","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Readings This year’s class video Last Year’s Class Video Post-Class Muddiest Points Clearest Points Other messages R Project files Please download the part2 folder from this dropbox folder link Be sure to unzip if necessary. In advance of class, please open the part2 Rstudio project (double click on the .rproj file), open part2.Rmd and knit (click the Knit button at the top of the file) this file. This will install packages that you need for the Rmd to run.\nReadings Required and suggested class readings can be found on the Readings tab by class. These readings may be done anytime before or after class, but they will supplement your understanding of the class materials and help make homework and project work easier.\nThis year’s class video See Slack for the zoom recording link\nLast Year’s Class Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\nMuddiest Points the benefits of tibble vs data frame and when to use which?\nIn this class we will always use tibble. Just remember that an object can be multiple types. A tibble is a data frame, but not vice versa. A tibble is really a data frame with “perks”. See this explanation from the tibble 1.0 package release\nThere are two main differences in the usage of a data frame vs a tibble: printing, and subsetting.\nTibbles have a refined print method that shows only the first 10 rows, and all the columns that fit on screen. This makes it much easier to work with large data. In addition to its name, each column reports its type, a nice feature borrowed from str():\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() class(mtcars) ## [1] \u0026quot;data.frame\u0026quot; mtcars ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 mtcars_tib \u0026lt;- as_tibble(mtcars) class(mtcars_tib) ## [1] \u0026quot;tbl_df\u0026quot; \u0026quot;tbl\u0026quot; \u0026quot;data.frame\u0026quot; mtcars_tib ## # A tibble: 32 × 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # … with 22 more rows ## # ℹ Use `print(n = ...)` to see more rows Another interesting difference is that tibbles don’t have row names, but a lot of built in data.frames in R do. But rownames are hard to get out. So, when you make a tibble of a data.frame you can tell the function to use the rownames as a column:\nmtcars_tib \u0026lt;- as_tibble(mtcars, rownames = \u0026quot;car_name\u0026quot;) mtcars_tib ## # A tibble: 32 × 12 ## car_name mpg cyl disp hp drat wt qsec vs am gear carb ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Mazda RX4 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 Mazda RX4 … 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 Hornet 4 D… 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 Hornet Spo… 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 Duster 360 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 Merc 240D 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 Merc 230 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 Merc 280 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # … with 22 more rows ## # ℹ Use `print(n = ...)` to see more rows Tibbles also clearly delineate [ and [[: [ always returns another tibble, [[ always returns a vector. No more drop = FALSE!\nIf we ask for the first column using the [] notation, we receive a numeric vector from a data frame, and a tibble/data.frame from the tibble.\nWe have not learned the [[]] yet because we have not talked about lists in R, but we will soon. The code below returns the first column as a vector for both a data frame and a tibble.\nmtcars[,1] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 ## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 ## [31] 15.0 21.4 mtcars_tib[,1] ## # A tibble: 32 × 1 ## car_name ## \u0026lt;chr\u0026gt; ## 1 Mazda RX4 ## 2 Mazda RX4 Wag ## 3 Datsun 710 ## 4 Hornet 4 Drive ## 5 Hornet Sportabout ## 6 Valiant ## 7 Duster 360 ## 8 Merc 240D ## 9 Merc 230 ## 10 Merc 280 ## # … with 22 more rows ## # ℹ Use `print(n = ...)` to see more rows mtcars[[1]] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 ## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 ## [31] 15.0 21.4 mtcars_tib[[1]] ## [1] \u0026quot;Mazda RX4\u0026quot; \u0026quot;Mazda RX4 Wag\u0026quot; \u0026quot;Datsun 710\u0026quot; ## [4] \u0026quot;Hornet 4 Drive\u0026quot; \u0026quot;Hornet Sportabout\u0026quot; \u0026quot;Valiant\u0026quot; ## [7] \u0026quot;Duster 360\u0026quot; \u0026quot;Merc 240D\u0026quot; \u0026quot;Merc 230\u0026quot; ## [10] \u0026quot;Merc 280\u0026quot; \u0026quot;Merc 280C\u0026quot; \u0026quot;Merc 450SE\u0026quot; ## [13] \u0026quot;Merc 450SL\u0026quot; \u0026quot;Merc 450SLC\u0026quot; \u0026quot;Cadillac Fleetwood\u0026quot; ## [16] \u0026quot;Lincoln Continental\u0026quot; \u0026quot;Chrysler Imperial\u0026quot; \u0026quot;Fiat 128\u0026quot; ## [19] \u0026quot;Honda Civic\u0026quot; \u0026quot;Toyota Corolla\u0026quot; \u0026quot;Toyota Corona\u0026quot; ## [22] \u0026quot;Dodge Challenger\u0026quot; \u0026quot;AMC Javelin\u0026quot; \u0026quot;Camaro Z28\u0026quot; ## [25] \u0026quot;Pontiac Firebird\u0026quot; \u0026quot;Fiat X1-9\u0026quot; \u0026quot;Porsche 914-2\u0026quot; ## [28] \u0026quot;Lotus Europa\u0026quot; \u0026quot;Ford Pantera L\u0026quot; \u0026quot;Ferrari Dino\u0026quot; ## [31] \u0026quot;Maserati Bora\u0026quot; \u0026quot;Volvo 142E\u0026quot; class(mtcars[,1]) ## [1] \u0026quot;numeric\u0026quot; class(mtcars_tib[,1]) ## [1] \u0026quot;tbl_df\u0026quot; \u0026quot;tbl\u0026quot; \u0026quot;data.frame\u0026quot; class(mtcars_tib[[1]]) ## [1] \u0026quot;character\u0026quot; As I was mentioning in class, there are some (older) functions that don’t like tibbles, but all you need to do is just make its primary class a data.frame as such:\nA handful of functions are don’t work with tibbles because they expect df[, 1] to return a vector, not a data frame. If you encounter one of these functions, use as.data.frame() to turn a tibble back to a data frame:\nmtcars_df \u0026lt;- as.data.frame(mtcars_tib) class(mtcars_df) ## [1] \u0026quot;data.frame\u0026quot; Back to muddy quotes:\npath files and knowing if you’re in a project or just an RMD\nR markdown vs R projects\nI hope to spend more time talking about this in class 4.\nggplot stuff was the most muddy, but I also haven’t done a lot of ggplot stuff before\nYes this was definitely expected for a brief intro, ggplot takes a while to get the hang of! We will use ggplot every class now, so we will go through it in bite sized pieces.\nUsing na=“NA” to pull in data and how to know that it’s needed.\nI will show more examples of this. Rule number one of importing data in any software is to look at your data, and figure out if what you see in the software is what you expect. Always look at your data! The read_excel(filename, na=\"NA\") is a strange case that isn’t actually very common to code data as “NA” directly, but I wanted to show you how it looks different when it does happen. Usually, missing data is just a blank space, which is automatically read in as the special NA data type in R.\n# If you did not include `na=NA` it would have been read in like this df1 \u0026lt;- tibble(a = c(\u0026quot;NA\u0026quot;,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;), b= 1:3, c = c(1,3,\u0026quot;NA\u0026quot;)) # If you did include `na = NA` it would have been read in like this df2 \u0026lt;- tibble(a = c(NA,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;), b= 1:3, c = c(1,3,NA)) # note the character types of the two DFs, and the way NA is printed df1 ## # A tibble: 3 × 3 ## a b c ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 NA 1 1 ## 2 C 2 3 ## 3 D 3 NA df2 ## # A tibble: 3 × 3 ## a b c ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026lt;NA\u0026gt; 1 1 ## 2 C 2 3 ## 3 D 3 NA I saw a lot of code with the two colons (“::”) in the middle. It is unclear to me if this is an alternative way to write some commands or if there is a certain context in which it is used.\nGood question, what this does is pulls a function from a package, so it works whether you have loaded the package (using library() or p_load()) or not. I mainly use it as a clue to you to where the function is coming from. Otherwise, you may not know you need to load that package to use it! For instance:\n# does not work, haven\u0026#39;t loaded the package janitor mtcars %\u0026gt;% tabyl(am, cyl) # does work mtcars %\u0026gt;% janitor::tabyl(am, cyl) ## am 4 6 8 ## 0 3 4 12 ## 1 8 3 2 # also works library(janitor) ## ## Attaching package: \u0026#39;janitor\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## chisq.test, fisher.test mtcars %\u0026gt;% tabyl(am, cyl) ## am 4 6 8 ## 0 3 4 12 ## 1 8 3 2 Clearest Points skim\nloading our excel to R studio\nLoading in the data and selecting the sheets that are most relevant to what we are looking to do was very clear and a nice foundation for future projects. I found that showing different ways of importing the data was helpful.\nI’m glad, the import tool in Rstudio is very nice, just remember to save the code in your Rmd.\nfunctionality of ggplot\ntidying the data\nFound out what eval=TRUE and eval=FALSE mean!\nGreat and I’ll show that again for anyone who was confused! (“still a little bit confused about the {r, EVAL} code”)\nOther messages Some people had trouble getting the fig.path= to work in the knitr options. I’m not sure what could be causing that but feel free to ask me during break.\nHere’s a good reference for all the code chunk options, if you want to read about it.\nlink to the course website that is in the overview tab in SAKAI links to last years materials.\nOops thank you great catch, fixed!\nSpeed is going great. I’m just worried as we progress through the course, it’ll be more difficult. Overall, really enjoying this class.\nI understand the concern, some things will get more difficult (I’m thinking across() in class 4, writing functions, and purrr), but we will also circle back to some things that might be familiar or maybe less complicated to start (stats models, making tables). Definitely keep asking questions and I will slow down as needed!\n","date":1674000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675229178,"objectID":"9ae245330f59c57e6f62568d635c26e4","permalink":"https://sph-r-programming-2023.netlify.app/class/02-class/","publishdate":"2023-01-18T00:00:00Z","relpermalink":"/class/02-class/","section":"class","summary":"R Project files Readings This year’s class video Last Year’s Class Video Post-Class Muddiest Points Clearest Points Other messages R Project files Please download the part2 folder from this dropbox folder link Be sure to unzip if necessary. In advance of class, please open the part2 Rstudio project (double click on the .rproj file), open part2.Rmd and knit (click the Knit button at the top of the file) this file.","tags":null,"title":"Part 2: Loading Data, data.frames, and ggplot2","type":"docs"},{"authors":null,"categories":null,"content":" Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting Type… …or… …to get Some text in a paragraph. More text in the next paragraph. Always use empty lines between paragraphs. Some text in a paragraph.\nMore text in the next paragraph. Always use empty lines between paragraphs.\n*Italic* _Italic_ Italic **Bold** __Bold__ Bold # Heading 1 Heading 1 ## Heading 2 Heading 2 ### Heading 3 Heading 3 (Go up to heading level 6 with ######) [Link text](http://www.example.com) Link text ![Image caption](/path/to/image.png) `Inline code` with backticks Inline code with backticks \u0026gt; Blockquote Blockquote\n- Things in - an unordered - list * Things in * an unordered * list Things in an unordered list 1. Things in 2. an ordered 3. list 1) Things in 2) an ordered 3) list Things in an ordered list Horizontal line --- Horizontal line *** Horizontal line\nMath Markdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here.\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\nType… …to get Based on the DAG, the regression model for estimating the effect of education on wages is $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, or $\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon$. Based on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\). To put an equation on its own line in a display block, wrap it in double dollar signs, like this:\nType…\nThe quadratic equation was an important part of high school math: $$ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ But now we just use computers to solve for $x$. …to get…\nThe quadratic equation was an important part of high school math:\n\\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]\nBut now we just use computers to solve for \\(x\\).\nBecause dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs $5.75 and this other costs $40”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”.\nTables There are 4 different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like pander (use pandoc.table()) or knitr (use kable()). The two most common are simple tables and pipe tables. You should look at the full documentation here.\nFor simple tables, type…\nRight Left Center Default ------- ------ ---------- ------- 12 12 12 12 123 123 123 123 1 1 1 1 Table: Caption goes here …to get…\nCaption goes here Right Left Center Default 12 12 12 12 123 123 123 123 1 1 1 1 For pipe tables, type…\n| Right | Left | Default | Center | |------:|:-----|---------|:------:| | 12 | 12 | 12 | 12 | | 123 | 123 | 123 | 123 | | 1 | 1 | 1 | 1 | Table: Caption goes here …to get…\nCaption goes here Right Left Default Center 12 12 12 12 123 123 123 123 1 1 1 1 Footnotes There are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags]. [^1]: This is a note. [^note-on-dags]: DAGs are neat. And here\u0026#39;s more of the document. …to get…\nHere is a footnote reference1 and here is another.2\nAnd here’s more of the document.\nThis is a note.↩︎ DAGs are neat.↩︎ You can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\nType…\nCausal inference is neat.^[But it can be hard too!] …to get…\nCausal inference is neat.1\nBut it can be hard too!↩︎ Front matter You can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; --- You can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n--- title: \u0026quot;My cool title: a subtitle\u0026quot; --- If you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n--- title: \u0026#39;An evaluation of \u0026quot;scare quotes\u0026quot;\u0026#39; --- Citations One of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\nAdd a bibliography: entry to the YAML metadata:\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib --- Choose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib csl: \u0026quot;https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\u0026quot; --- Some of the most common CSLs are:\nChicago author-date Chicago note-bibliography Chicago full note-bibliography (no shortened notes or ibids) APA 7th edition MLA 8th edition Cite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\nType… …to get… Causal inference is neat [@Rohrer:2018; @AngristPischke:2015]. Causal inference is neat (Rohrer 2018; Angrist and Pischke 2015). Causal inference is neat [see @Rohrer:2018, p. 34; also @AngristPischke:2015, chapter 1]. Causal inference is neat (see Rohrer 2018, 34; also Angrist and Pischke 2015, chap. 1). Angrist and Pischke say causal inference is neat [-@AngristPischke:2015; see also @Rohrer:2018]. Angrist and Pischke say causal inference is neat (2015; see also Rohrer 2018). @AngristPischke:2015 [chapter 1] say causal inference is neat, and @Rohrer:2018 agrees. Angrist and Pischke (2015, chap. 1) say causal inference is neat, and Rohrer (2018) agrees. After compiling, you should have a perfectly formatted bibliography added to the end of your document too:\nAngrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\nOther references These websites have additional details and examples and practice tools:\nCommonMark’s Markdown tutorial: A quick interactive Markdown tutorial. Markdown tutorial: Another interactive tutorial to practice using Markdown. Markdown cheatsheet: Useful one-page reminder of Markdown syntax. The Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown. ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"2fcfa99344c0deb9152fd925ddf0e508","permalink":"https://sph-r-programming-2023.netlify.app/reference/markdown/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/reference/markdown/","section":"reference","summary":"Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting Type… …or… …to get Some text in a paragraph. More text in the next paragraph.","tags":null,"title":"Using Markdown","type":"docs"},{"authors":null,"categories":null,"content":" Key terms Add chunks Chunk names Chunk options Inline chunks Output formats R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).\nThe documentation for R Markdown is extremely comprehensive, and their tutorials and cheatsheets are excellent—rely on those.\nHere are the most important things you’ll need to know about R Markdown in this class:\nKey terms Document: A Markdown file where you type stuff\nChunk: A piece of R code that is included in your document. It looks like this:\n```{r} # Code goes here ``` There must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not knit correctly.\nKnit: When you “knit” a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the knitted document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can knit by clicking on the “Knit” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows.\nAdd chunks There are three ways to insert chunks:\nPress ⌘⌥I on macOS or control + alt + I on Windows\nClick on the “Insert” button at the top of the editor window\nManually type all the backticks and curly braces (don’t do this)\nChunk names You can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\nTo add a name, include it immediately after the {r in the first line of the chunk. Names cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.\n```{r name-of-this-chunk} # Code goes here ``` Chunk options There are a bunch of different options you can set for each chunk. You can see a complete list in the RMarkdown Reference Guide or at knitr’s website.\nOptions go inside the {r} section of the chunk:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE} # Code goes here ``` The most common chunk options are these:\nfig.width=5 and fig.height=3 (or whatever number you want): Set the dimensions for figures echo=FALSE: The code is not shown in the final document, but the results are message=FALSE: Any messages that R generates (like all the notes that appear after you load a package) are omitted warning=FALSE: Any warnings that R generates are omitted include=FALSE: The chunk still runs, but the code and results are not included in the final document You can also set chunk options by clicking on the little gear icon in the top right corner of any chunk:\nInline chunks You can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r find-avg-mpg, echo=FALSE} avg_mpg \u0026lt;- mean(mtcars$mpg) ``` The average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon. … would knit into this:\nThe average fuel efficiency for cars from 1974 was 20.1 miles per gallon.\nOutput formats You can specify what kind of document you create when you knit in the YAML front matter.\ntitle: \u0026quot;My document\u0026quot; output: html_document: default pdf_document: default word_document: default You can also click on the down arrow on the “Knit” button to choose the output and generate the appropriate YAML. If you click on the gear icon next to the “Knit” button and choose “Output options”, you change settings for each specific output type, like default figure dimensions or whether or not a table of contents is included.\nThe first output type listed under output: will be what is generated when you click on the “Knit” button or press the keyboard shortcut (⌘⇧K on macOS; control + shift + K on Windows). If you choose a different output with the “Knit” button menu, that output will be moved to the top of the output section.\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical output section might look like:\n--- title: \u0026quot;My document\u0026quot; author: \u0026quot;My name\u0026quot; date: \u0026quot;January 13, 2020\u0026quot; output: html_document: toc: yes fig_caption: yes fig_height: 8 fig_width: 10 pdf_document: latex_engine: xelatex # More modern PDF typesetting engine toc: yes word_document: toc: yes fig_caption: yes fig_height: 4 fig_width: 5 --- ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"1c588ba5e1b21bc2d9ce3418cca23497","permalink":"https://sph-r-programming-2023.netlify.app/reference/rmarkdown/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/reference/rmarkdown/","section":"reference","summary":"Key terms Add chunks Chunk names Chunk options Inline chunks Output formats R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).","tags":null,"title":"Using R Markdown","type":"docs"},{"authors":null,"categories":null,"content":" RStudio.cloud RStudio on your computer Install R Install RStudio Install tidyverse Install tinytex You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.\nRStudio.cloud R is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for labs and problem sets.\nGo to https://rstudio.cloud/ and create an account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you.\nRStudio on your computer RStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of RStudio.cloud and install all these things locally. This is also important if you want to customize fonts, since RStudio.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\nInstall R First you need to install R itself (the engine).\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\nIf you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-3.5.1.pkg; as of right now, the current version is 3.6.1) and download it.\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nInstall RStudio Next, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nSelect the installer that corresponds with your computer’s operating system (Windows or macOS):\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\nDouble click on RStudio to run it (check your applications folder or start menu).\nInstall tidyverse R packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse2 for instance, consists of dozens of packages that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\nInstall tinytex When you knit to PDF, R uses a special scientific typesetting program named LaTeX (pronounced “lay-tek” or “lah-tex”; for goofy nerdy reasons, the x is technically the “ch” sound in “Bach”, but most people just say it as “k”—saying “layteks” is frowned on for whatever reason).\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB! To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nHere’s how to install tinytex so you can knit to pretty PDFs:\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console. Run tinytex::install_tinytex() in the console. Wait for a bit while R downloads and installs everything you need. The end! You should now be able to knit to PDF. It’s a goofy name, but CRAN is where most R packages—and R itself—lives.↩︎\nA universe of packages centered around tidy data, including ggplot2↩︎\n","date":1576540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"32d2aa5db9c906dd4dae32456ff00876","permalink":"https://sph-r-programming-2023.netlify.app/reference/install/","publishdate":"2019-12-17T00:00:00Z","relpermalink":"/reference/install/","section":"reference","summary":"RStudio.cloud RStudio on your computer Install R Install RStudio Install tidyverse Install tinytex You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.","tags":null,"title":"Installing R, RStudio, tidyverse, and tinytex","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Readings Class Video Post-Class Muddiest points Clearest Points Other messages R Project files Please download the part3 folder from this dropbox folder link.\nUse the grey “download” button to download the whole folder, please keep the file structure and folder organization exactly the same as we need this for class. Be sure to unzip if necessary. You may move the folder part3 wherever you like on your computer. Be sure to unzip if necessary.\nIn advance of class, please open the part3 Rstudio project (double click on the .rproj file), open part3.Rmd and knit (click the Knit button at the top of the file) this file. This will install packages that you need for the Rmd to run.\nReadings Required and suggested class readings can be found on the Readings tab by class. These readings may be done anytime before or after class, but they will supplement your understanding of the class materials and help make homework and project work easier.\nClass Video The class video is here, but I forgot to video tape the part about here::here(). If I have a chance I will re-record myself talking about it, but in the meantime, click here for Ted’s video from last year, start at linked time and watch for about 6 minutes, which explains similar ideas.\nView last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\nMuddiest points themes in ggplot\nCheck out this reference about ggplot themes first.\nHere’s a couple examples using this one plot, so you can see how the theme changes the look of the figure, when you use built in themes from the ggplot2 package (yes it only works in ggplot figures, for the person who asked about that)\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() p \u0026lt;- ggplot(mtcars, aes(x = mpg, y = carb, color = factor(cyl))) + geom_point() + labs(title = \u0026quot;My scatterplot\u0026quot;) p Here are some built in themes:\np + theme_bw() p + theme_minimal() p + theme_classic() However you can make more customized themes or plot changes where you use the theme() function to add in a lot of other elements. You can use this add on function to choose specific parts of the plot that you want to change, like this example from the above reference. Anything specified here will override the built in theme selected first. There are many options, and looking at specific examples will help. I am always, always googling how to change parts of the theme/plot like this, because there are just so many options it’s too hard to remember them all.\np + theme_classic() + theme( plot.title = element_text(face = \u0026quot;bold\u0026quot;, size = 12), legend.background = element_rect(fill = \u0026quot;white\u0026quot;, size = 4, colour = \u0026quot;white\u0026quot;), legend.justification = c(0, 1), legend.position = c(0, 1), axis.ticks = element_line(colour = \u0026quot;grey70\u0026quot;, size = 0.2), panel.grid.major = element_line(colour = \u0026quot;grey70\u0026quot;, size = 0.2), panel.grid.minor = element_blank() ) Here’s a simpler example just changing the title (from the above reference):\np + theme(plot.title = element_text(size = 16)) p + theme(plot.title = element_text(face = \u0026quot;bold\u0026quot;, colour = \u0026quot;red\u0026quot;)) p + theme(plot.title = element_text(hjust = 1)) here()\nAgreed, it’s very confusing, more in class 4!\nCould you please clarify about the use of select(one_of) and the count command that was mentioned in dplyr cheatsheet?\nThese are very different, if you are talking about select() vs count(). One thing to note is that since I recorded that class, one_of() has been superseded/replaced by any_of() and all_of().\nFirst, select() is a function to subset columns.\nlibrary(palmerpenguins) Here we specify the columns we want in the order we want:\npenguins %\u0026gt;% select(bill_length_mm, island, species, year) ## # A tibble: 344 × 4 ## bill_length_mm island species year ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 39.1 Torgersen Adelie 2007 ## 2 39.5 Torgersen Adelie 2007 ## 3 40.3 Torgersen Adelie 2007 ## 4 NA Torgersen Adelie 2007 ## 5 36.7 Torgersen Adelie 2007 ## 6 39.3 Torgersen Adelie 2007 ## 7 38.9 Torgersen Adelie 2007 ## 8 39.2 Torgersen Adelie 2007 ## 9 34.1 Torgersen Adelie 2007 ## 10 42 Torgersen Adelie 2007 ## # … with 334 more rows ## # ℹ Use `print(n = ...)` to see more rows Here, we pass a vector of character names, both of which work:\npenguins %\u0026gt;% select(c(\u0026quot;bill_length_mm\u0026quot;,\u0026quot;island\u0026quot;,\u0026quot;species\u0026quot;,\u0026quot;year\u0026quot;)) ## # A tibble: 344 × 4 ## bill_length_mm island species year ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 39.1 Torgersen Adelie 2007 ## 2 39.5 Torgersen Adelie 2007 ## 3 40.3 Torgersen Adelie 2007 ## 4 NA Torgersen Adelie 2007 ## 5 36.7 Torgersen Adelie 2007 ## 6 39.3 Torgersen Adelie 2007 ## 7 38.9 Torgersen Adelie 2007 ## 8 39.2 Torgersen Adelie 2007 ## 9 34.1 Torgersen Adelie 2007 ## 10 42 Torgersen Adelie 2007 ## # … with 334 more rows ## # ℹ Use `print(n = ...)` to see more rows penguins %\u0026gt;% select(any_of(c(\u0026quot;bill_length_mm\u0026quot;,\u0026quot;island\u0026quot;,\u0026quot;species\u0026quot;,\u0026quot;year\u0026quot;))) ## # A tibble: 344 × 4 ## bill_length_mm island species year ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 39.1 Torgersen Adelie 2007 ## 2 39.5 Torgersen Adelie 2007 ## 3 40.3 Torgersen Adelie 2007 ## 4 NA Torgersen Adelie 2007 ## 5 36.7 Torgersen Adelie 2007 ## 6 39.3 Torgersen Adelie 2007 ## 7 38.9 Torgersen Adelie 2007 ## 8 39.2 Torgersen Adelie 2007 ## 9 34.1 Torgersen Adelie 2007 ## 10 42 Torgersen Adelie 2007 ## # … with 334 more rows ## # ℹ Use `print(n = ...)` to see more rows This might be useful if we have that character vector already saved from some other data work we are doing:\ncolnames_needed \u0026lt;- c(\u0026quot;bill_length_mm\u0026quot;,\u0026quot;island\u0026quot;,\u0026quot;species\u0026quot;,\u0026quot;year\u0026quot;) penguins %\u0026gt;% select(colnames_needed) ## Note: Using an external vector in selections is ambiguous. ## ℹ Use `all_of(colnames_needed)` instead of `colnames_needed` to silence this message. ## ℹ See \u0026lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html\u0026gt;. ## This message is displayed once per session. ## # A tibble: 344 × 4 ## bill_length_mm island species year ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 39.1 Torgersen Adelie 2007 ## 2 39.5 Torgersen Adelie 2007 ## 3 40.3 Torgersen Adelie 2007 ## 4 NA Torgersen Adelie 2007 ## 5 36.7 Torgersen Adelie 2007 ## 6 39.3 Torgersen Adelie 2007 ## 7 38.9 Torgersen Adelie 2007 ## 8 39.2 Torgersen Adelie 2007 ## 9 34.1 Torgersen Adelie 2007 ## 10 42 Torgersen Adelie 2007 ## # … with 334 more rows ## # ℹ Use `print(n = ...)` to see more rows But the key about any_of and all_of is what it allows. any_of() allows column names that don’t exist! Using no tidyselect helper or all_of() does not allow this. Which you use depends on what you want to allow to happen.\ncolnames_needed \u0026lt;- c(\u0026quot;bill_length_mm\u0026quot;,\u0026quot;island\u0026quot;,\u0026quot;species\u0026quot;,\u0026quot;year\u0026quot;,\u0026quot;MISSING\u0026quot;) # penguins %\u0026gt;% select((colnames_needed)) # does not work penguins %\u0026gt;% select(any_of(colnames_needed)) # works! ## # A tibble: 344 × 4 ## bill_length_mm island species year ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 39.1 Torgersen Adelie 2007 ## 2 39.5 Torgersen Adelie 2007 ## 3 40.3 Torgersen Adelie 2007 ## 4 NA Torgersen Adelie 2007 ## 5 36.7 Torgersen Adelie 2007 ## 6 39.3 Torgersen Adelie 2007 ## 7 38.9 Torgersen Adelie 2007 ## 8 39.2 Torgersen Adelie 2007 ## 9 34.1 Torgersen Adelie 2007 ## 10 42 Torgersen Adelie 2007 ## # … with 334 more rows ## # ℹ Use `print(n = ...)` to see more rows # penguins %\u0026gt;% select(all_of(colnames_needed)) # does not work any_of() is an example of a tidyselect helper, which we will see a lot more of when we start using across() with mutate() and summarize() in class 4. See this long list of useful tidyselect functions for more.\nOn the other hand, count() is mainly to count the number of unique values in a column/vector:\npenguins %\u0026gt;% count(species) ## # A tibble: 3 × 2 ## species n ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie 152 ## 2 Chinstrap 68 ## 3 Gentoo 124 This created a new tibble, that summarizes the species column by counting the number of each type of species. This works for any type of vector but is most useful with character and factor columns. You can also use multiple columns here to see all possible combinations:\npenguins %\u0026gt;% count(species, year) ## # A tibble: 9 × 3 ## species year n ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie 2007 50 ## 2 Adelie 2008 50 ## 3 Adelie 2009 52 ## 4 Chinstrap 2007 26 ## 5 Chinstrap 2008 18 ## 6 Chinstrap 2009 24 ## 7 Gentoo 2007 34 ## 8 Gentoo 2008 46 ## 9 Gentoo 2009 44 Clearest Points filter, select, arrange, pipes\nSuper! I want to take the time to mention (and hopefully not confuse everyone) that the pipe has recently (2021) been integrated into “base R”, that is, it’s loaded without loading the tidyverse package. HOWEVER it is this symbol |\u0026gt; and does not behave exactly like the tidyverse pipe %\u0026gt;% (actually from the magrittr package within the tidyverse package). For all the usual uses it works the same, so it could be used interchangeably in this class. Just know that if you see that type of pipe being used, assume it’s doing basically the same thing. Even R for Data Science is likely moving to use the native/base pipe, see this explanation. Probably next year’s class I will switch everything over to use this, though I still just use %\u0026gt;% in my own work as it’s slightly more flexible for more “advanced” usage.\npenguins |\u0026gt; count(species, year) ## # A tibble: 9 × 3 ## species year n ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie 2007 50 ## 2 Adelie 2008 50 ## 3 Adelie 2009 52 ## 4 Chinstrap 2007 26 ## 5 Chinstrap 2008 18 ## 6 Chinstrap 2009 24 ## 7 Gentoo 2007 34 ## 8 Gentoo 2008 46 ## 9 Gentoo 2009 44 Other messages Density ridges are cool!\nI agree!\n","date":1674604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675815290,"objectID":"a0c01f3889200201f6df018341b3db8f","permalink":"https://sph-r-programming-2023.netlify.app/class/03-class/","publishdate":"2023-01-25T00:00:00Z","relpermalink":"/class/03-class/","section":"class","summary":"R Project files Readings Class Video Post-Class Muddiest points Clearest Points Other messages R Project files Please download the part3 folder from this dropbox folder link.\nUse the grey “download” button to download the whole folder, please keep the file structure and folder organization exactly the same as we need this for class. Be sure to unzip if necessary. You may move the folder part3 wherever you like on your computer.","tags":null,"title":"Part 3: ggplot2, factors, boxplots, dplyr: subsetting","type":"docs"},{"authors":null,"categories":null,"content":" R Project files This year’s class video Last Year’s Class Video Slides Another useful video Post-Class Muddiest points Clearest points Other points R Project files Please download the part4 folder from this dropbox folder link. Be sure to unzip if necessary. “Knit” the part4.Rmd file to install packages and make sure everything is working with data loading.\n(We did not finish part4, and will finish it in class 5.)\nThis year’s class video See Slack for the zoom recording link\nLast Year’s Class Video View last year’s class and materials here.\nSlides During “Muddiest Parts” review, we will go over these slides\nAnother useful video Dr. Kelly Bodwin’s forcats/factor\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\nMuddiest points I’ve noticed some confusion about what I call “saving your work”, so we’ll go over these slides.\nusing factors, what you’re doing and the benefit of turning things into factors in mutate\nI usually turn something into a factor for plotting (especially if I have a categorial numeric variable), and we’ll see more examples of that. We also later will see how it matters in statistical modeling/regression. It also is often easier to manage levels/categories this way, as we will see when we talk about the forcats package again in class 6.\ncase_when is not easy\nCorrect! Also some other comments on wanting more practice with case_when(). We will continue to see examples with this as we finish part5 and in other classes. It’s a very handy function so I use it a lot! See also the video above about factors with another explanation.\nThe function for converting a vector back from factor to character - I thought I had it, but I didn’t.\nOh, I didn’t show this!\n# make a character vector myvec \u0026lt;- c(\u0026quot;medium\u0026quot;, \u0026quot;low\u0026quot;, \u0026quot;high\u0026quot;, \u0026quot;low\u0026quot;) myvec_fac \u0026lt;- factor(myvec) myvec_fac ## [1] medium low high low ## Levels: high low medium class(myvec_fac) ## [1] \u0026quot;factor\u0026quot; # get the levels out levels(myvec_fac) ## [1] \u0026quot;high\u0026quot; \u0026quot;low\u0026quot; \u0026quot;medium\u0026quot; # Note we can \u0026quot;test\u0026quot; the classes of something like so: is.factor(myvec_fac) ## [1] TRUE is.character(myvec_fac) ## [1] FALSE # Now we can change it back myvec2 \u0026lt;- as.character(myvec_fac) myvec2 ## [1] \u0026quot;medium\u0026quot; \u0026quot;low\u0026quot; \u0026quot;high\u0026quot; \u0026quot;low\u0026quot; class(myvec2) ## [1] \u0026quot;character\u0026quot; levels(myvec2) # no levels, because it\u0026#39;s not a factor ## NULL # we could also change to numeric, how do you think it picks which number is which? myvec3 \u0026lt;- as.numeric(myvec_fac) myvec3 ## [1] 3 2 1 2 # levels in order is assigned 1, 2, 3 table(myvec_fac, myvec3) ## myvec3 ## myvec_fac 1 2 3 ## high 1 0 0 ## low 0 2 0 ## medium 0 0 1 # change the level order myvec_fac2 \u0026lt;- factor(myvec, levels = c(\u0026quot;low\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;high\u0026quot;)) levels(myvec_fac2) ## [1] \u0026quot;low\u0026quot; \u0026quot;medium\u0026quot; \u0026quot;high\u0026quot; myvec4 \u0026lt;- as.numeric(myvec_fac2) myvec4 ## [1] 2 1 3 1 table(myvec_fac2, myvec4) ## myvec4 ## myvec_fac2 1 2 3 ## low 2 0 0 ## medium 0 1 0 ## high 0 0 1 factor vs as.factor\nEssentially the same. From the help documentation ?factor: “as.factor coerces its argument to a factor. It is an abbreviated (sometimes faster) form of factor.”\nI would like to know when you recommend that we save a new data set once we create new covariates. Also, it is unclear to me how you add the variable to the existing data.\nIf I want to use that column/covariate again, I save it (so almost always, as I don’t often make a column without using it later). I usually save it back into the original data set I’m working with, that is, overwrite that object to be updated with the new column. As long as I keep track of my changes this is definitely ok. It can get confusing having too many versions of a data set floating around. If something is broken, the worst that happens is that you’ll just need to start from the beginning and reload your data (the data file will remain untouched) and re-run the code.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.4.0 ✔ purrr 1.0.1 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.10 ## ✔ tidyr 1.2.1 ✔ stringr 1.5.0 ## ✔ readr 2.1.3 ✔ forcats 0.5.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(palmerpenguins) # does not save the new column, just prints result penguins %\u0026gt;% mutate(newvec = bill_length_mm/bill_depth_mm) ## # A tibble: 344 × 9 ## species island bill_length_mm bill_de…¹ flipp…² body_…³ sex year newvec ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 2.09 ## 2 Adelie Torgersen 39.5 17.4 186 3800 fema… 2007 2.27 ## 3 Adelie Torgersen 40.3 18 195 3250 fema… 2007 2.24 ## 4 Adelie Torgersen NA NA NA NA \u0026lt;NA\u0026gt; 2007 NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 fema… 2007 1.90 ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 1.91 ## 7 Adelie Torgersen 38.9 17.8 181 3625 fema… 2007 2.19 ## 8 Adelie Torgersen 39.2 19.6 195 4675 male 2007 2 ## 9 Adelie Torgersen 34.1 18.1 193 3475 \u0026lt;NA\u0026gt; 2007 1.88 ## 10 Adelie Torgersen 42 20.2 190 4250 \u0026lt;NA\u0026gt; 2007 2.08 ## # … with 334 more rows, and abbreviated variable names ¹​bill_depth_mm, ## # ²​flipper_length_mm, ³​body_mass_g # saves new column in a data frame that is called penguins2 penguins2 \u0026lt;- penguins %\u0026gt;% mutate(newvec = bill_length_mm/bill_depth_mm) glimpse(penguins2) ## Rows: 344 ## Columns: 9 ## $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island \u0026lt;fct\u0026gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … ## $ bill_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … ## $ flipper_length_mm \u0026lt;int\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… ## $ body_mass_g \u0026lt;int\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … ## $ sex \u0026lt;fct\u0026gt; male, female, female, NA, female, male, female, male… ## $ year \u0026lt;int\u0026gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… ## $ newvec \u0026lt;dbl\u0026gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767… glimpse(penguins) # has not been changed ## Rows: 344 ## Columns: 8 ## $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island \u0026lt;fct\u0026gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … ## $ bill_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … ## $ flipper_length_mm \u0026lt;int\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… ## $ body_mass_g \u0026lt;int\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … ## $ sex \u0026lt;fct\u0026gt; male, female, female, NA, female, male, female, male… ## $ year \u0026lt;int\u0026gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… # saves new column in a data frame in the original data frame penguins # *overwrites penguins* penguins \u0026lt;- penguins %\u0026gt;% mutate(newvec = bill_length_mm/bill_depth_mm) glimpse(penguins) ## Rows: 344 ## Columns: 9 ## $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island \u0026lt;fct\u0026gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … ## $ bill_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … ## $ flipper_length_mm \u0026lt;int\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… ## $ body_mass_g \u0026lt;int\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … ## $ sex \u0026lt;fct\u0026gt; male, female, female, NA, female, male, female, male… ## $ year \u0026lt;int\u0026gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… ## $ newvec \u0026lt;dbl\u0026gt; 2.090909, 2.270115, 2.238889, NA, 1.901554, 1.907767… arrange vs filter\narrange orders or sorts your data and does not remove or add anything, while filter removes rows.\nClearest points working directory, here reordering factors mutate tibble vs data frame factors filtering\nGlad to hear we’re making progress!\nOther points Is there a list somewhere of all potential colors?\nA couple answers:\nSee this page for a list of “named” colors in R., or the ggplot2 cookbook for a smaller list We will talk more about palettes when we finish part4 but there are many, many. I suggest finding a package or two that has the palettes you like and working with those. See a bunch listed here (scroll down in the readme).. My favorites are ggthemes and colorBlindness. I’m curious what the best practice is for stringing things together versus breaking them into pieces. For example, if I was trying to make a binary variable where all values were classified as larger or greater than the mean, I could use mean() inside several other functions like mutate(). Alternately I could calculate mean() [meanxx \u0026lt;- mean(xxx)] and save it as an object, and then use the other functions on that value. I’m curious because it seems like if you did too many functions at once and were getting errors, it would be hard to tell what was wrong. But if you did it in a more stepwise fashion, you could see (for example) that mean() wasn’t working because there were NAs in your dataset. More importantly, I think if you were getting an erroneous answer (not an error, but a wrong answer, like if you calculated the mean of a variable but your NA’s were marked with “-88” and so R considered these actual observations) you might not know if you joined too many functions together and didn’t “see” what was happening under the hood. I’m curious how to deal with that.\nI copied over this whole question because I think it is an excellent one, and well said (hope you don’t mind)! I think this is something that evolves as you become more experienced in coding and debugging, and as you find your own style of coding. I will talk some about debugging later, but what you are saying about breaking things up into pieces absolutely helps with that.\nThe one thing to make sure of is that if you are saving intermediate steps, such as meanxx \u0026lt;- mean(mydata$xx) and using it later, but then you update the data set (filter, replace NAs, fix an incorrect data entry, whatever), you need to make sure to update/re-calculate that mean object as it no longer matches your newer data set! So there is more to keep track of, in that case.\nI will say that if you are keeping track of all the steps well, then functionally it does not matter too much, so if it makes things easier to break it up, do that! If you like to chain everything together (often I do) you can run each piece by highlighting the code and running just that part to see what is going on, and this is something I do often.\nYour example is something I would probably do, though, as using the mean inside mutate does make me a bit nervous. For example, let’s use median because it’s easier to check my work at the end:\nlibrary(janitor) # for tabyl() ## ## Attaching package: \u0026#39;janitor\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## chisq.test, fisher.test # there are NAs in here: median(penguins$body_mass_g) ## [1] NA # let\u0026#39;s save the median as a vector of length 1, remove NAs tmpmedian \u0026lt;- median(penguins$body_mass_g, na.rm = TRUE) tmpmedian ## [1] 4050 penguins \u0026lt;- penguins %\u0026gt;% mutate( large_mass = case_when( body_mass_g \u0026gt;= tmpmedian ~ \u0026quot;yes\u0026quot;, body_mass_g \u0026lt; tmpmedian ~ \u0026quot;no\u0026quot; # this allows NAs to remain NA )) penguins %\u0026gt;% tabyl(large_mass) ## large_mass n percent valid_percent ## no 170 0.494186047 0.497076 ## yes 172 0.500000000 0.502924 ## \u0026lt;NA\u0026gt; 2 0.005813953 NA # if I had just used median without checking for NAs, they all are NA: penguins %\u0026gt;% mutate(large_mass = 1*(body_mass_g \u0026gt;= median(body_mass_g))) %\u0026gt;% tabyl(large_mass) ## large_mass n percent valid_percent ## NA 344 1 NA # Note if I just want females, this no longer makes sense: penguins %\u0026gt;% filter(sex==\u0026quot;female\u0026quot;) %\u0026gt;% mutate( large_mass = case_when( body_mass_g \u0026gt;= tmpmedian ~ \u0026quot;yes\u0026quot;, body_mass_g \u0026lt; tmpmedian ~ \u0026quot;no\u0026quot; # this allows NAs to remain NA )) %\u0026gt;% tabyl(large_mass) ## large_mass n percent ## no 107 0.6484848 ## yes 58 0.3515152 # but this would: penguins %\u0026gt;% filter(sex==\u0026quot;female\u0026quot;) %\u0026gt;% mutate( large_mass = case_when( body_mass_g \u0026gt;= median(body_mass_g, na.rm = TRUE) ~ \u0026quot;yes\u0026quot;, body_mass_g \u0026lt; median(body_mass_g, na.rm = TRUE) ~ \u0026quot;no\u0026quot; )) %\u0026gt;% tabyl(large_mass) ## large_mass n percent ## no 80 0.4848485 ## yes 85 0.5151515 ","date":1675209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675816175,"objectID":"ac7533426a3114e90edf09c0635b197a","permalink":"https://sph-r-programming-2023.netlify.app/class/04-class/","publishdate":"2023-02-01T00:00:00Z","relpermalink":"/class/04-class/","section":"class","summary":"R Project files This year’s class video Last Year’s Class Video Slides Another useful video Post-Class Muddiest points Clearest points Other points R Project files Please download the part4 folder from this dropbox folder link. Be sure to unzip if necessary. “Knit” the part4.Rmd file to install packages and make sure everything is working with data loading.\n(We did not finish part4, and will finish it in class 5.)","tags":null,"title":"Part 4. dplyr: mutate, group_by, summarize, across","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Last Year’s Class Video (Part 5) Another useful video Useful ggplot2 links Post-Class R Project files Please download the part5 folder from this dropbox folder link. Be sure to unzip if necessary. “Knit” the code/part5.Rmd file to install packages and make sure everything is working with data loading.\nLast Year’s Class Video (Part 5) View last year’s class and materials here.\nAnother useful video Dr. Kelly Bodwin’s Reshaping Data Video\nFor a short version, watch the pivot_longer excerpt about “working backwards” from a plot. Then watch the pivot_wider excerpt\nUseful ggplot2 links ggplot2 cookbook, scales ggplot2 guide_axis(), which lets you avoid overlapping axis labels ggplot2 faq axes Post-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\n","date":1675728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675817807,"objectID":"0ddf3e2b3a9f5347c88f83033fb01ff2","permalink":"https://sph-r-programming-2023.netlify.app/class/05-class/","publishdate":"2023-02-07T00:00:00Z","relpermalink":"/class/05-class/","section":"class","summary":"R Project files Last Year’s Class Video (Part 5) Another useful video Useful ggplot2 links Post-Class R Project files Please download the part5 folder from this dropbox folder link. Be sure to unzip if necessary. “Knit” the code/part5.Rmd file to install packages and make sure everything is working with data loading.\nLast Year’s Class Video (Part 5) View last year’s class and materials here.\nAnother useful video Dr. Kelly Bodwin’s Reshaping Data Video","tags":null,"title":"Part 4 (contd) + Part 5: Data summarizing, reshaping, and wrangling with multiple tables","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Class Video Post-Class R Project files In this class we finished the part5 material from this folder link. Please download this folder and be sure to unzip if necessary. Knit the part6.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\n","date":1644364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675228243,"objectID":"119022d4a0cb3ad45bc292e062e9e05a","permalink":"https://sph-r-programming-2023.netlify.app/class/06-class/","publishdate":"2022-02-09T00:00:00Z","relpermalink":"/class/06-class/","section":"class","summary":"R Project files Class Video Post-Class R Project files In this class we finished the part5 material from this folder link. Please download this folder and be sure to unzip if necessary. Knit the part6.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.","tags":null,"title":"Part 5 contd (Class 6): Data summarizing, reshaping, and wrangling with multiple tables (contd)","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Class Video Post-Class R Project files Please download the part7 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part7.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\n","date":1645574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675228243,"objectID":"a696c93d764e2bfb447300660fcf2be7","permalink":"https://sph-r-programming-2023.netlify.app/class/08-class/","publishdate":"2022-02-23T00:00:00Z","relpermalink":"/class/08-class/","section":"class","summary":"R Project files Class Video Post-Class R Project files Please download the part7 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part7.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture?","tags":null,"title":"Part 7 (Class 8): Lists/Functions/Intro to Purrr","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Class 7 Video Post-Class R Project files Last class we finished up part5 materials. This is class 7, and we will start with part6 now (sorry, we’re going to be off by one from now on). Please download the part6 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part6.Rmd to install any required packages.\nThis section is mainly a practice, with some additional ggplot lessons. There will be lots of time for breakout room challenges so that you can get practice working on these data wrangling and graphing problems together.\nClass 7 Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\n","date":1644969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675228243,"objectID":"026700f4d4068083b37f98f89edf4682","permalink":"https://sph-r-programming-2023.netlify.app/class/07-class/","publishdate":"2022-02-16T00:00:00Z","relpermalink":"/class/07-class/","section":"class","summary":"R Project files Class 7 Video Post-Class R Project files Last class we finished up part5 materials. This is class 7, and we will start with part6 now (sorry, we’re going to be off by one from now on). Please download the part6 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part6.Rmd to install any required packages.\nThis section is mainly a practice, with some additional ggplot lessons.","tags":null,"title":"Part 6 (Class 7): More data wrangling and ggplot","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Class Video Post-Class R Project files Please download the part8 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part8.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\n","date":1646179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675228243,"objectID":"6fce0ded8aa03d77081bcdf32570ef18","permalink":"https://sph-r-programming-2023.netlify.app/class/09-class/","publishdate":"2022-03-02T00:00:00Z","relpermalink":"/class/09-class/","section":"class","summary":"R Project files Class Video Post-Class R Project files Please download the part8 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part8.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture?","tags":null,"title":"Part 8 (Class 9). Intro to stats/`broom`/More Purrr","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Class Video Post-Class R Project files Please download the part9 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part9.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://bit.ly/bsta504_postclass_survey\n","date":1646784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675228243,"objectID":"3fea5612523ac7da2f3ba696739f7198","permalink":"https://sph-r-programming-2023.netlify.app/class/10-class/","publishdate":"2022-03-09T00:00:00Z","relpermalink":"/class/10-class/","section":"class","summary":"R Project files Class Video Post-Class R Project files Please download the part9 sub-folder from this dropbox link. Be sure to unzip if necessary. Knit the part9.Rmd to install any required packages.\nClass Video View last year’s class and materials here.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture?","tags":null,"title":"Part 9 (Class 10): More Stats Stuff/Summary Tables","type":"docs"},{"authors":null,"categories":null,"content":" R Project files Class Video R Project files In this class we finished part 9, and covered about half of part 10 in the dropbox folder. Be sure to unzip if necessary.\nClass Video View last year’s class and materials here.\n","date":1647388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673222924,"objectID":"187acf4fd964c835bff8f91f793da537","permalink":"https://sph-r-programming-2023.netlify.app/class/11-class/","publishdate":"2022-03-16T00:00:00Z","relpermalink":"/class/11-class/","section":"class","summary":"R Project files Class Video R Project files In this class we finished part 9, and covered about half of part 10 in the dropbox folder. Be sure to unzip if necessary.\nClass Video View last year’s class and materials here.","tags":null,"title":"Class 11: Finish Part 9 + Part 10: Advanced Functions and Loose Ends","type":"docs"},{"authors":null,"categories":null,"content":" Required Remember, this reading is mostly supplemental and will help you if there are concepts that are unclear in class.\nR and RStudio Basics - make sure to watch the videos. Vectors and Data Frames Rstudio projects Optional Markdown Basics This is a short reference on how to do formatting in Markdown. This is optional, but may be a helpful reference as you continue on and work with Markdown and RMarkdown.\nhttps://sph-r-programming-2023.netlify.app/reference/markdown.html\nSwirl Basics I’m going to highlight another resource for learning basic R concepts: swirl. This is a software package for R.\nTo start it, run the following code in the console in RStudio Cloud:\nlibrary(swirl) swirl() You’ll want to take a look at the R Programming course, especially the following sections:\nBasic Building Blocks Sequences of Numbers Vectors Missing values ","date":1673395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673396780,"objectID":"57c6d6996ee98125a5375a3865ff4c4c","permalink":"https://sph-r-programming-2023.netlify.app/reading/01-reading/","publishdate":"2023-01-11T00:00:00Z","relpermalink":"/reading/01-reading/","section":"reading","summary":"Required Remember, this reading is mostly supplemental and will help you if there are concepts that are unclear in class.\nR and RStudio Basics - make sure to watch the videos. Vectors and Data Frames Rstudio projects Optional Markdown Basics This is a short reference on how to do formatting in Markdown. This is optional, but may be a helpful reference as you continue on and work with Markdown and RMarkdown.","tags":null,"title":"Introduction to R/RStudio/Vectors","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: dplyr::relocate() Function of the Week: dplyr::relocate() Trisha Marsh 2022-02-23 relocate() In this document, I will introduce the relocate() function from dplyr and show what it’s for.\n#load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(gt) #example dataset library(palmerpenguins) data(penguins) What is it for? The relocate() function is used to change the order of columns in a dataframe. This can be done in a few different ways.\nArguments are the data frame, followed by the column(s) to be moved, then the new position.\nMove one column If a new position is not specified, the default is to move the column to the first position. This can be used to move one or more columns. Use .before or .after to designate the new column position.\npenguins %\u0026gt;% head() %\u0026gt;% gt() species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Adelie Torgersen 39.1 18.7 181 3750 male 2007 Adelie Torgersen 39.5 17.4 186 3800 female 2007 Adelie Torgersen 40.3 18.0 195 3250 female 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen 36.7 19.3 193 3450 female 2007 Adelie Torgersen 39.3 20.6 190 3650 male 2007 penguins %\u0026gt;% relocate(year, bill_depth_mm) %\u0026gt;% head() %\u0026gt;% gt() year bill_depth_mm species island bill_length_mm flipper_length_mm body_mass_g sex 2007 18.7 Adelie Torgersen 39.1 181 3750 male 2007 17.4 Adelie Torgersen 39.5 186 3800 female 2007 18.0 Adelie Torgersen 40.3 195 3250 female 2007 NA Adelie Torgersen NA NA NA NA 2007 19.3 Adelie Torgersen 36.7 193 3450 female 2007 20.6 Adelie Torgersen 39.3 190 3650 male penguins %\u0026gt;% relocate(year, .after = island) %\u0026gt;% head() %\u0026gt;% gt() species island year bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex Adelie Torgersen 2007 39.1 18.7 181 3750 male Adelie Torgersen 2007 39.5 17.4 186 3800 female Adelie Torgersen 2007 40.3 18.0 195 3250 female Adelie Torgersen 2007 NA NA NA NA NA Adelie Torgersen 2007 36.7 19.3 193 3450 female Adelie Torgersen 2007 39.3 20.6 190 3650 male # or relocate(penguins, year, .after = island) %\u0026gt;% head() %\u0026gt;% gt() species island year bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex Adelie Torgersen 2007 39.1 18.7 181 3750 male Adelie Torgersen 2007 39.5 17.4 186 3800 female Adelie Torgersen 2007 40.3 18.0 195 3250 female Adelie Torgersen 2007 NA NA NA NA NA Adelie Torgersen 2007 36.7 19.3 193 3450 female Adelie Torgersen 2007 39.3 20.6 190 3650 male Move a block of columns Similar to functions like select(), a block of columns can be chosen.\npenguins %\u0026gt;% head() %\u0026gt;% gt() species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Adelie Torgersen 39.1 18.7 181 3750 male 2007 Adelie Torgersen 39.5 17.4 186 3800 female 2007 Adelie Torgersen 40.3 18.0 195 3250 female 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen 36.7 19.3 193 3450 female 2007 Adelie Torgersen 39.3 20.6 190 3650 male 2007 penguins %\u0026gt;% relocate(body_mass_g:year, .before = bill_length_mm) %\u0026gt;% head() %\u0026gt;% gt() species island body_mass_g sex year bill_length_mm bill_depth_mm flipper_length_mm Adelie Torgersen 3750 male 2007 39.1 18.7 181 Adelie Torgersen 3800 female 2007 39.5 17.4 186 Adelie Torgersen 3250 female 2007 40.3 18.0 195 Adelie Torgersen NA NA 2007 NA NA NA Adelie Torgersen 3450 female 2007 36.7 19.3 193 Adelie Torgersen 3650 male 2007 39.3 20.6 190 Move using tidyselect helpers penguins %\u0026gt;% head() %\u0026gt;% gt() species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Adelie Torgersen 39.1 18.7 181 3750 male 2007 Adelie Torgersen 39.5 17.4 186 3800 female 2007 Adelie Torgersen 40.3 18.0 195 3250 female 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen 36.7 19.3 193 3450 female 2007 Adelie Torgersen 39.3 20.6 190 3650 male 2007 penguins %\u0026gt;% relocate(contains(\u0026quot;_mm\u0026quot;), .after = species) %\u0026gt;% head() %\u0026gt;% gt() species bill_length_mm bill_depth_mm flipper_length_mm island body_mass_g sex year Adelie 39.1 18.7 181 Torgersen 3750 male 2007 Adelie 39.5 17.4 186 Torgersen 3800 female 2007 Adelie 40.3 18.0 195 Torgersen 3250 female 2007 Adelie NA NA NA Torgersen NA NA 2007 Adelie 36.7 19.3 193 Torgersen 3450 female 2007 Adelie 39.3 20.6 190 Torgersen 3650 male 2007 Move columns based on their type Another handy option is to rearrange the columns based on the type of data. The penguins dataset contains both factors and numbers.\npenguins %\u0026gt;% head() %\u0026gt;% gt() species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Adelie Torgersen 39.1 18.7 181 3750 male 2007 Adelie Torgersen 39.5 17.4 186 3800 female 2007 Adelie Torgersen 40.3 18.0 195 3250 female 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen 36.7 19.3 193 3450 female 2007 Adelie Torgersen 39.3 20.6 190 3650 male 2007 penguins %\u0026gt;% relocate(where(is.numeric), .after = where(is.factor)) %\u0026gt;% head() %\u0026gt;% gt() species island sex bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year Adelie Torgersen male 39.1 18.7 181 3750 2007 Adelie Torgersen female 39.5 17.4 186 3800 2007 Adelie Torgersen female 40.3 18.0 195 3250 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen female 36.7 19.3 193 3450 2007 Adelie Torgersen male 39.3 20.6 190 3650 2007 Bonus: Rename An additional feature of this function is the ability to rename columns. Again, the default is to move the renamed column to the first position in the dataframe. This is easily addressed by specifying the position with .before or .after. This is a nice option if you want to move a column and rename it all at once.\npenguins %\u0026gt;% head() %\u0026gt;% gt() species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Adelie Torgersen 39.1 18.7 181 3750 male 2007 Adelie Torgersen 39.5 17.4 186 3800 female 2007 Adelie Torgersen 40.3 18.0 195 3250 female 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen 36.7 19.3 193 3450 female 2007 Adelie Torgersen 39.3 20.6 190 3650 male 2007 penguins %\u0026gt;% relocate(site = island) %\u0026gt;% head() %\u0026gt;% gt() site species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Torgersen Adelie 39.1 18.7 181 3750 male 2007 Torgersen Adelie 39.5 17.4 186 3800 female 2007 Torgersen Adelie 40.3 18.0 195 3250 female 2007 Torgersen Adelie NA NA NA NA NA 2007 Torgersen Adelie 36.7 19.3 193 3450 female 2007 Torgersen Adelie 39.3 20.6 190 3650 male 2007 penguins %\u0026gt;% relocate(site = island, .after = species) %\u0026gt;% head() %\u0026gt;% gt() species site bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year Adelie Torgersen 39.1 18.7 181 3750 male 2007 Adelie Torgersen 39.5 17.4 186 3800 female 2007 Adelie Torgersen 40.3 18.0 195 3250 female 2007 Adelie Torgersen NA NA NA NA NA 2007 Adelie Torgersen 36.7 19.3 193 3450 female 2007 Adelie Torgersen 39.3 20.6 190 3650 male 2007 Is it helpful? This is a very useful function, especially with large dataframes with many columns. It is also very useful when new columns are added and need to be placed in specific positions. relocate() allows you to easily rearrange columns to better display the data for presentation and analysis.\n","date":1645574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"6bf9e38490963b1e6bc9153ddf33844b","permalink":"https://sph-r-programming-2023.netlify.app/functions/dplyr_relocate/","publishdate":"2022-02-23T00:00:00Z","relpermalink":"/functions/dplyr_relocate/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: dplyr::relocate() Function of the Week: dplyr::relocate() Trisha Marsh 2022-02-23 relocate() In this document, I will introduce the relocate() function from dplyr and show what it’s for. #load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.","tags":null,"title":"dplyr::relocate()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Geom_smooth Function of the Week: Geom_smooth Mia Truman 2022-02-23 geom_smooth In this document, I will introduce the geom_smooth() function and show what it’s for.\n#load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.8 ## ✓ tidyr 1.2.0 ✓ stringr 1.4.0 ## ✓ readr 2.1.2 ✓ forcats 0.5.1 ## Warning: package \u0026#39;tidyr\u0026#39; was built under R version 4.1.2 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.1.2 ## Warning: package \u0026#39;dplyr\u0026#39; was built under R version 4.1.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() #read in the dataset library(readxl) library(ggplot2) #load the two datasets I will use rats \u0026lt;- read_excel(\u0026quot;/Users/miatruman/Documents/R/512/data/CH05Q09.xls\u0026quot;) smoking \u0026lt;- read_excel(\u0026quot;smoke_1.xlsx\u0026quot;,na = \u0026quot;NA\u0026quot;) What is it for?\nThe function geom_smooth is useful for visually showing trends in a plot. Specifically it can help aid the eye when there is overplotting. Additionally it is the function used to find a linear fit. If not specified, the method that geom_smooth() uses to create a fit depends on how much data there is. If not specified, the function will decide based on the size of data. “Loess” is used for less than 1000 observations (polynomial regression fitting), otherwise “gam” is used (generalized additive models). Other options are “rlm” and “lm.”\nThe following example is a linear model. When plotting X vs Y, a negative linear trend can be seen visually. Geom_smooth(method = “lm”) creates a regression line and a confidence interval to more clearly illustrate the relationship between x and y.The default formula is Y~X, but this can be changed to include a quadratic formula. The following is an example from Applied Regression Analysis and Other Multivariable Methods (Kleinbaum, D. G., Kupper, L. L., Nizam, A., \u0026amp; Rosenberg, E. S. (2014). In Applied regression analysis and other multivariable methods (p. 90). essay, Cengage Learning.).\n#make sample ggplot rats_plot \u0026lt;- ggplot(rats, aes(x = LOGDOSE, y = LOGCONC, na.rm = TRUE )) + geom_point()+ labs(title = \u0026quot;dose–response curve for vitamin K in rats\u0026quot;, y = \u0026quot;concentration of clotting agent (log)\u0026quot;, x = \u0026quot;dosage level (log)\u0026quot;)+ theme(plot.title = element_text(hjust = 0.5)) rats_plot #now add the geom_smooth without specifying a method rats_plot+geom_smooth()+ggtitle(\u0026quot;with geom_smooth() (no method specified. default = loess)\u0026quot;) ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula \u0026#39;y ~ x\u0026#39; #geom_smooth with specifying a method. it assumes we want y~x rats_plot+geom_smooth(method = \u0026quot;lm\u0026quot;)+ggtitle(\u0026quot;with method = lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; #without the confidence interval rats_plot+geom_smooth(method = \u0026quot;lm\u0026quot;, se = F) +ggtitle(\u0026quot;se = f to get rid of confidence interval\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Another Example: How geom_smooth() can visually assist the user when speculating whether there is a linear trend. In this example, a trend is unclear. It looks that perhaps days to death and years smoked are positively correlated, but it’s not obvious. Adding geom_smooth() makes it more clear. smoking_plot \u0026lt;- ggplot(smoking, aes(x = years_smoked, y = days_to_death, na.rm = TRUE ))+geom_point()+labs(title = \u0026quot;years smoked vs days to death\u0026quot;, y = \u0026quot;days to death\u0026quot;, x = \u0026quot;years smoked\u0026quot;)+ theme(plot.title = element_text(hjust = 0.5)) #plot it: smoking_plot ## Warning: Removed 978 rows containing missing values (geom_point). smoking_plot+geom_smooth() ## `geom_smooth()` using method = \u0026#39;gam\u0026#39; and formula \u0026#39;y ~ s(x, bs = \u0026quot;cs\u0026quot;)\u0026#39; ## Warning: Removed 978 rows containing non-finite values (stat_smooth). ## Removed 978 rows containing missing values (geom_point). Is it helpful?\nYes. geom_smooth is vital to showing trends in data. It is a method that allows us to insert a linear regression line into a ggplot. It is helpful if the type of model that fits your data is known, but also helpful to quickly see a relationship between the variables. It is very relevant to statistical analysis. ","date":1645574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"3926cbe4b55fbc39d143b1819397eb08","permalink":"https://sph-r-programming-2023.netlify.app/functions/ggplot2_geom_smooth/","publishdate":"2022-02-23T00:00:00Z","relpermalink":"/functions/ggplot2_geom_smooth/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Geom_smooth Function of the Week: Geom_smooth Mia Truman 2022-02-23 geom_smooth In this document, I will introduce the geom_smooth() function and show what it’s for. #load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.8 ## ✓ tidyr 1.2.0 ✓ stringr 1.4.0 ## ✓ readr 2.1.2 ✓ forcats 0.","tags":null,"title":"ggplot2::geom_smooth()","type":"docs"},{"authors":null,"categories":null,"content":" Required Functions in R for Data Science Iteration in R for Data Science Learn to purrr Suggested Vectors and Lists - Jenny Bryan Introduction to map() - Jenny Bryan Re-visit these required readings from earlier:\nIntroduction to Functions and Arguments Introduction to Lists ","date":1645574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"84eea7e2ac7daba0422f51df6e252e34","permalink":"https://sph-r-programming-2023.netlify.app/reading/08-reading/","publishdate":"2022-02-23T00:00:00Z","relpermalink":"/reading/08-reading/","section":"reading","summary":" Required Functions in R for Data Science Iteration in R for Data Science Learn to purrr Suggested Vectors and Lists - Jenny Bryan Introduction to map() - Jenny Bryan Re-visit these required readings from earlier:\nIntroduction to Functions and Arguments Introduction to Lists ","tags":null,"title":"Part 7 (Class 8): Lists/Functions/Intro to Purrr","type":"docs"},{"authors":null,"categories":null,"content":" Continue with Part 6 Readings.\n","date":1644969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"5256604b09b011b85f6df88676e905f4","permalink":"https://sph-r-programming-2023.netlify.app/reading/07-reading/","publishdate":"2022-02-16T00:00:00Z","relpermalink":"/reading/07-reading/","section":"reading","summary":"Continue with Part 6 Readings.","tags":null,"title":"Part 6 (Class 7): More data wrangling and ggplot","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Laura Jacobson Febuary 16, 2022 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing\nFor this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.\ndrop_na() In this document, I will introduce the [drop_na] function and show what it’s for. This is part of dplyr, which I load through tidyverse.\n#load tidyverse library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() #load penguins data library(palmerpenguins) data(penguins) options(tibble.width = Inf) What is it for? The drop_na function drops rows containing missing values. This function accepts 2 arguments, the dataframe and … (tidy-select), or the columns to check for missing values. If empty, all columns are used. Another way of putting this, is that it only keeps complete rows, unless specifying for a specific column.\nExamples #Viewing a slice of penguins data penguins%\u0026gt;% slice(1:15) ## # A tibble: 15 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## 7 Adelie Torgersen 38.9 17.8 181 3625 ## 8 Adelie Torgersen 39.2 19.6 195 4675 ## 9 Adelie Torgersen 34.1 18.1 193 3475 ## 10 Adelie Torgersen 42 20.2 190 4250 ## 11 Adelie Torgersen 37.8 17.1 186 3300 ## 12 Adelie Torgersen 37.8 17.3 180 3700 ## 13 Adelie Torgersen 41.1 17.6 182 3200 ## 14 Adelie Torgersen 38.6 21.2 191 3800 ## 15 Adelie Torgersen 34.6 21.1 198 4400 ## sex year ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 male 2007 ## 2 female 2007 ## 3 female 2007 ## 4 \u0026lt;NA\u0026gt; 2007 ## 5 female 2007 ## 6 male 2007 ## 7 female 2007 ## 8 male 2007 ## 9 \u0026lt;NA\u0026gt; 2007 ## 10 \u0026lt;NA\u0026gt; 2007 ## 11 \u0026lt;NA\u0026gt; 2007 ## 12 \u0026lt;NA\u0026gt; 2007 ## 13 female 2007 ## 14 male 2007 ## 15 male 2007 #Dropping all NA penguins%\u0026gt;% slice(1:15) %\u0026gt;% drop_na() ## # A tibble: 10 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen 36.7 19.3 193 3450 ## 5 Adelie Torgersen 39.3 20.6 190 3650 ## 6 Adelie Torgersen 38.9 17.8 181 3625 ## 7 Adelie Torgersen 39.2 19.6 195 4675 ## 8 Adelie Torgersen 41.1 17.6 182 3200 ## 9 Adelie Torgersen 38.6 21.2 191 3800 ## 10 Adelie Torgersen 34.6 21.1 198 4400 ## sex year ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 male 2007 ## 2 female 2007 ## 3 female 2007 ## 4 female 2007 ## 5 male 2007 ## 6 female 2007 ## 7 male 2007 ## 8 female 2007 ## 9 male 2007 ## 10 male 2007 What we may have wanted to do is drop NA in a specific column.\n#Drop NA by body mass penguins%\u0026gt;% slice(1:15) %\u0026gt;% drop_na(body_mass_g) ## # A tibble: 14 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen 36.7 19.3 193 3450 ## 5 Adelie Torgersen 39.3 20.6 190 3650 ## 6 Adelie Torgersen 38.9 17.8 181 3625 ## 7 Adelie Torgersen 39.2 19.6 195 4675 ## 8 Adelie Torgersen 34.1 18.1 193 3475 ## 9 Adelie Torgersen 42 20.2 190 4250 ## 10 Adelie Torgersen 37.8 17.1 186 3300 ## 11 Adelie Torgersen 37.8 17.3 180 3700 ## 12 Adelie Torgersen 41.1 17.6 182 3200 ## 13 Adelie Torgersen 38.6 21.2 191 3800 ## 14 Adelie Torgersen 34.6 21.1 198 4400 ## sex year ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 male 2007 ## 2 female 2007 ## 3 female 2007 ## 4 female 2007 ## 5 male 2007 ## 6 female 2007 ## 7 male 2007 ## 8 \u0026lt;NA\u0026gt; 2007 ## 9 \u0026lt;NA\u0026gt; 2007 ## 10 \u0026lt;NA\u0026gt; 2007 ## 11 \u0026lt;NA\u0026gt; 2007 ## 12 female 2007 ## 13 male 2007 ## 14 male 2007 Now it only dropped the rows that had a missing values for body mass.\nThis is important for running tests and for plotting. Dropping missing values looks different depending on your data type or research question. For example, here is a box plot of species and body mass\npenguins %\u0026gt;% ggplot() + aes(x = species, y=body_mass_g) + geom_boxplot() ## Warning: Removed 2 rows containing non-finite values (stat_boxplot). Here is the same plot with body mass NAs dropped\npenguins %\u0026gt;% drop_na() %\u0026gt;% ggplot() + aes(x = species, y=body_mass_g) + geom_boxplot() It looks the same\nWhat is we are working with character such as sex\npenguins %\u0026gt;% ggplot() + aes(x = species, fill = species) + geom_bar() + facet_wrap(vars(sex)) Now we have this other category that we might now want on the chart.\npenguins %\u0026gt;% drop_na(sex) %\u0026gt;% ggplot() + aes(x = species, fill = species) + geom_bar() + facet_wrap(vars(sex)) Is it helpful? Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\nMissing data is a fact of life! It is important to remember that missing data is information and we don’t want to just throw it away, especially if it’s not random. Depending on the analysis we may need to do sensitivity analyses etc, so we want to be cautious when dropping NA. However, it can be very useful to get calculations to run, make nice plots, and to help make sense of our data. Filtering out NAs is another choice, that might be more appropriate depending on the analysis.\n","date":1644969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"eebc1c0eeda6cd9c78567c00568810f6","permalink":"https://sph-r-programming-2023.netlify.app/functions/tidyr_drop_na/","publishdate":"2022-02-16T00:00:00Z","relpermalink":"/functions/tidyr_drop_na/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Laura Jacobson Febuary 16, 2022 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing For this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.","tags":null,"title":"tidyr::drop_na()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: dplyr::coalesce() Function of the Week: dplyr::coalesce() Yan Liu 2/9/2022 dplyr::coalesce() In this document, I will introduce the coalesce() function and show what it’s for.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() What is it for? Given a set of vectors, coalesce( )finds the first non-missing value at each position. The arguments of this function is the vectors. It can be used to replace and compare missing data.\nFirst, it can use a single value to replace the missing data.\nx\u0026lt;-c(1,2,NA,NA,1,2,3) #create example vector class(x) ## [1] \u0026quot;numeric\u0026quot; coalesce(x,4)#apply coalesce ## [1] 1 2 4 4 1 2 3 x\u0026lt;-c(1,2,\u0026quot;b\u0026quot;,NA,NA,1,2) class(x) ## [1] \u0026quot;character\u0026quot; coalesce(x,\u0026quot;a\u0026quot;) ## [1] \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;b\u0026quot; \u0026quot;a\u0026quot; \u0026quot;a\u0026quot; \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; df\u0026lt;-tibble(x=c(1,NA,3), y=c(NA,5,6)) df ## # A tibble: 3 × 2 ## x y ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 NA ## 2 NA 5 ## 3 3 6 class(df) ## [1] \u0026quot;tbl_df\u0026quot; \u0026quot;tbl\u0026quot; \u0026quot;data.frame\u0026quot; coalesce(df$x,2) ## [1] 1 2 3 It can replace NA with the same class of the vector, and it can not replace NA in the data_frame directly.\nSecond, it can compare and replace NA in the first vector with the value in other vectors.\nx\u0026lt;-c(1,1,NA,1,NA,NA) y\u0026lt;-c(2,NA,2,2,2,NA) z\u0026lt;-c(3,NA,3,NA,3,3) coalesce(x,y,z) ## [1] 1 1 2 1 2 3 Different size and type can not be compared and replaced.\nThird, it can compare and replace NA in the list.\nx\u0026lt;-list(c(1,NA,NA),c(NA,4,NA),c(NA,6,7)) class(x) ## [1] \u0026quot;list\u0026quot; coalesce(!!!x) ## [1] 1 4 7 It requires each column has the same size.\nIs it helpful? Yes, when we want to deal with missing data, “coalesce()” is very useful. It can replace NA and compare different vector and list. But it has strict requirements on the type and length of data. If we want to replace NA with some special data, “replace_na()” is much more powerful than coalesce(). It can replace NA with numerical or character whatever the vector is. It can also replace NA in data frame or replace NUlls in a list.\nx\u0026lt;-c(1,2,NA,NA) class(x) ## [1] \u0026quot;numeric\u0026quot; replace_na(x,\u0026quot;a\u0026quot;) ## [1] \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;a\u0026quot; \u0026quot;a\u0026quot; df\u0026lt;-tibble(x=c(1,NA,NA,3), y=c(NA,5,6,NA)) df ## # A tibble: 4 × 2 ## x y ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 NA ## 2 NA 5 ## 3 NA 6 ## 4 3 NA df%\u0026gt;%replace_na(list(x=0,y=1)) ## # A tibble: 4 × 2 ## x y ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 ## 2 0 5 ## 3 0 6 ## 4 3 1 df\u0026lt;-tibble(z=list(1:5,NULL,10:20)) df ## # A tibble: 3 × 1 ## z ## \u0026lt;list\u0026gt; ## 1 \u0026lt;int [5]\u0026gt; ## 2 \u0026lt;NULL\u0026gt; ## 3 \u0026lt;int [11]\u0026gt; dg\u0026lt;-df%\u0026gt;%replace_na(list(z=list(5))) dg ## # A tibble: 3 × 1 ## z ## \u0026lt;list\u0026gt; ## 1 \u0026lt;int [5]\u0026gt; ## 2 \u0026lt;dbl [1]\u0026gt; ## 3 \u0026lt;int [11]\u0026gt; What’s more, if we want to convert an annoying value to NA, we can use “na_if”.\ny \u0026lt;- c(1,2,3) na_if(y,1) ## [1] NA 2 3 ","date":1644364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"2925415dcb93b113abc82f8bddcdc6b5","permalink":"https://sph-r-programming-2023.netlify.app/functions/dplyr_coalesce/","publishdate":"2022-02-09T00:00:00Z","relpermalink":"/functions/dplyr_coalesce/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: dplyr::coalesce() Function of the Week: dplyr::coalesce() Yan Liu 2/9/2022 dplyr::coalesce() In this document, I will introduce the coalesce() function and show what it’s for. library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() What is it for?","tags":null,"title":"dplyr::coalesce()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: get_dupes () Function of the Week: get_dupes () Becky 2022-02-09 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing\nFor this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(readxl) library(skimr) library(readr) library(dplyr) #load janitor which contains get_dupes () library(janitor) ## ## Attaching package: \u0026#39;janitor\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## chisq.test, fisher.test #example dataset library(palmerpenguins) data(penguins) get_dupes () In this document, I will introduce the get_dupes () function and show what it’s for. get_dupes() is from the janitor package.\nWhat is it for? This function identifies duplicate row values of specified variables across a given dataset. It takes the arguments (data, variable); variables can be a mix of types (dbl, chr, etc). It returns a dataframe (or tibble if tibble is used) with duplicate rows for all variables specified. A column, “dupe_count”, is inserted containing the number of duplicates. If no variable is specified, it looks for duplicate rows across all variables in the dataset.\nnum_1 \u0026lt;- c(1:6) col_1 \u0026lt;- c(\u0026quot;red\u0026quot;, \u0026quot;orange\u0026quot;, \u0026quot;yellow\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;blue\u0026quot;) numbers_colors_1 \u0026lt;- data.frame(num_1, col_1) numbers_colors_1 ## num_1 col_1 ## 1 1 red ## 2 2 orange ## 3 3 yellow ## 4 4 green ## 5 5 green ## 6 6 blue get_dupes (numbers_colors_1) ## No variable names specified - using all columns. ## No duplicate combinations found of: num_1, col_1 ## [1] num_1 col_1 dupe_count ## \u0026lt;0 rows\u0026gt; (or 0-length row.names) num_2 \u0026lt;- c(1, 2, 3, 4, 4, 4) col_2 \u0026lt;- c(\u0026quot;red\u0026quot;, \u0026quot;orange\u0026quot;, \u0026quot;yellow\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;green\u0026quot;) numbers_colors_2 \u0026lt;- data.frame(num_2, col_2) numbers_colors_2 ## num_2 col_2 ## 1 1 red ## 2 2 orange ## 3 3 yellow ## 4 4 green ## 5 4 green ## 6 4 green get_dupes (numbers_colors_2) ## No variable names specified - using all columns. ## num_2 col_2 dupe_count ## 1 4 green 3 ## 2 4 green 3 ## 3 4 green 3 num_3 \u0026lt;- c(1, 2, 3, 4, 5, 5, 6, 6, 6) col_3 \u0026lt;- c(\u0026quot;red\u0026quot;, \u0026quot;orange\u0026quot;, \u0026quot;yellow\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;pink\u0026quot;) numbers_colors_3 \u0026lt;- data.frame(num_3, col_3) numbers_colors_3 ## num_3 col_3 ## 1 1 red ## 2 2 orange ## 3 3 yellow ## 4 4 green ## 5 5 blue ## 6 5 blue ## 7 6 blue ## 8 6 blue ## 9 6 pink get_dupes(numbers_colors_3) ## No variable names specified - using all columns. ## num_3 col_3 dupe_count ## 1 5 blue 2 ## 2 5 blue 2 ## 3 6 blue 2 ## 4 6 blue 2 get_dupes(numbers_colors_3, num_3) ## num_3 dupe_count col_3 ## 1 5 2 blue ## 2 5 2 blue ## 3 6 3 blue ## 4 6 3 blue ## 5 6 3 pink get_dupes(numbers_colors_3, col_3) ## col_3 dupe_count num_3 ## 1 blue 4 5 ## 2 blue 4 5 ## 3 blue 4 6 ## 4 blue 4 6 #orders by level for character/factor data get_dupes (penguins) ## No variable names specified - using all columns. ## No duplicate combinations found of: species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex, year ## # A tibble: 0 × 9 ## # … with 9 variables: species \u0026lt;fct\u0026gt;, island \u0026lt;fct\u0026gt;, bill_length_mm \u0026lt;dbl\u0026gt;, ## # bill_depth_mm \u0026lt;dbl\u0026gt;, flipper_length_mm \u0026lt;int\u0026gt;, body_mass_g \u0026lt;int\u0026gt;, sex \u0026lt;fct\u0026gt;, ## # year \u0026lt;int\u0026gt;, dupe_count \u0026lt;int\u0026gt; get_dupes (penguins, species) ## # A tibble: 344 × 9 ## species dupe_count island bill_length_mm bill_depth_mm flipper_length_mm ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie 152 Torgersen 39.1 18.7 181 ## 2 Adelie 152 Torgersen 39.5 17.4 186 ## 3 Adelie 152 Torgersen 40.3 18 195 ## 4 Adelie 152 Torgersen NA NA NA ## 5 Adelie 152 Torgersen 36.7 19.3 193 ## 6 Adelie 152 Torgersen 39.3 20.6 190 ## 7 Adelie 152 Torgersen 38.9 17.8 181 ## 8 Adelie 152 Torgersen 39.2 19.6 195 ## 9 Adelie 152 Torgersen 34.1 18.1 193 ## 10 Adelie 152 Torgersen 42 20.2 190 ## # … with 334 more rows, and 3 more variables: body_mass_g \u0026lt;int\u0026gt;, sex \u0026lt;fct\u0026gt;, ## # year \u0026lt;int\u0026gt; get_dupes (penguins, species, island) ## # A tibble: 344 × 9 ## species island dupe_count bill_length_mm bill_depth_mm flipper_length_mm ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Biscoe 44 37.8 18.3 174 ## 2 Adelie Biscoe 44 37.7 18.7 180 ## 3 Adelie Biscoe 44 35.9 19.2 189 ## 4 Adelie Biscoe 44 38.2 18.1 185 ## 5 Adelie Biscoe 44 38.8 17.2 180 ## 6 Adelie Biscoe 44 35.3 18.9 187 ## 7 Adelie Biscoe 44 40.6 18.6 183 ## 8 Adelie Biscoe 44 40.5 17.9 187 ## 9 Adelie Biscoe 44 37.9 18.6 172 ## 10 Adelie Biscoe 44 40.5 18.9 180 ## # … with 334 more rows, and 3 more variables: body_mass_g \u0026lt;int\u0026gt;, sex \u0026lt;fct\u0026gt;, ## # year \u0026lt;int\u0026gt; get_dupes (penguins, species, island, year) ## # A tibble: 344 × 9 ## species island year dupe_count bill_length_mm bill_depth_mm flipper_length_… ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Biscoe 2007 10 37.8 18.3 174 ## 2 Adelie Biscoe 2007 10 37.7 18.7 180 ## 3 Adelie Biscoe 2007 10 35.9 19.2 189 ## 4 Adelie Biscoe 2007 10 38.2 18.1 185 ## 5 Adelie Biscoe 2007 10 38.8 17.2 180 ## 6 Adelie Biscoe 2007 10 35.3 18.9 187 ## 7 Adelie Biscoe 2007 10 40.6 18.6 183 ## 8 Adelie Biscoe 2007 10 40.5 17.9 187 ## 9 Adelie Biscoe 2007 10 37.9 18.6 172 ## 10 Adelie Biscoe 2007 10 40.5 18.9 180 ## # … with 334 more rows, and 2 more variables: body_mass_g \u0026lt;int\u0026gt;, sex \u0026lt;fct\u0026gt; #orders numeric data get_dupes(penguins, body_mass_g, sex) ## # A tibble: 283 × 9 ## body_mass_g sex dupe_count species island bill_length_mm bill_depth_mm ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2850 female 2 Adelie Biscoe 36.5 16.6 ## 2 2850 female 2 Adelie Biscoe 36.4 17.1 ## 3 2900 female 4 Adelie Biscoe 34.5 18.1 ## 4 2900 female 4 Adelie Dream 33.1 16.1 ## 5 2900 female 4 Adelie Torgers… 38.6 17 ## 6 2900 female 4 Chinstrap Dream 43.2 16.6 ## 7 3000 female 2 Adelie Dream 37 16.9 ## 8 3000 female 2 Adelie Dream 37.3 16.8 ## 9 3050 female 4 Adelie Torgers… 35.9 16.6 ## 10 3050 female 4 Adelie Torgers… 35.2 15.9 ## # … with 273 more rows, and 2 more variables: flipper_length_mm \u0026lt;int\u0026gt;, ## # year \u0026lt;int\u0026gt; Artists \u0026lt;- read_csv(\u0026quot;https://media.githubusercontent.com/media/MuseumofModernArt/collection/master/Artists.csv\u0026quot;) ## Rows: 15222 Columns: 9 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (5): DisplayName, ArtistBio, Nationality, Gender, Wiki QID ## dbl (4): ConstituentID, BeginDate, EndDate, ULAN ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Artists %\u0026gt;% get_dupes() ## No variable names specified - using all columns. ## No duplicate combinations found of: ConstituentID, DisplayName, ArtistBio, Nationality, Gender, BeginDate, EndDate, Wiki QID, ULAN ## # A tibble: 0 × 10 ## # … with 10 variables: ConstituentID \u0026lt;dbl\u0026gt;, DisplayName \u0026lt;chr\u0026gt;, ArtistBio \u0026lt;chr\u0026gt;, ## # Nationality \u0026lt;chr\u0026gt;, Gender \u0026lt;chr\u0026gt;, BeginDate \u0026lt;dbl\u0026gt;, EndDate \u0026lt;dbl\u0026gt;, ## # Wiki QID \u0026lt;chr\u0026gt;, ULAN \u0026lt;dbl\u0026gt;, dupe_count \u0026lt;int\u0026gt; Artists %\u0026gt;% get_dupes(Nationality) ## # A tibble: 15,201 × 10 ## Nationality dupe_count ConstituentID DisplayName ArtistBio Gender BeginDate ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Albanian 3 29622 Anri Sala Albanian,… Male 1974 ## 2 Albanian 3 30621 Adrian Paci Albanian,… Male 1969 ## 3 Albanian 3 31324 Edi Rama Albanian,… Male 1964 ## 4 Algerian 5 1880 M. Fiorini Algerian,… Male 1922 ## 5 Algerian 5 43595 Lyès Salem Algerian,… Male 1973 ## 6 Algerian 5 43626 Djamila Sah… Algerian,… Female 1950 ## 7 Algerian 5 49216 Neïl Beloufa Algerian-… Male 1985 ## 8 Algerian 5 70052 El Hadi Jaz… Algerian,… Male 1970 ## 9 American 5194 1 Robert Arne… American,… Male 1930 ## 10 American 5194 3 Bill Arnold American,… Male 1941 ## # … with 15,191 more rows, and 3 more variables: EndDate \u0026lt;dbl\u0026gt;, Wiki QID \u0026lt;chr\u0026gt;, ## # ULAN \u0026lt;dbl\u0026gt; Artists %\u0026gt;% get_dupes(Nationality, Gender) ## # A tibble: 15,157 × 10 ## Nationality Gender dupe_count ConstituentID DisplayName ArtistBio BeginDate ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Albanian Male 3 29622 Anri Sala Albanian,… 1974 ## 2 Albanian Male 3 30621 Adrian Paci Albanian,… 1969 ## 3 Albanian Male 3 31324 Edi Rama Albanian,… 1964 ## 4 Algerian Male 4 1880 M. Fiorini Algerian,… 1922 ## 5 Algerian Male 4 43595 Lyès Salem Algerian,… 1973 ## 6 Algerian Male 4 49216 Neïl Beloufa Algerian-… 1985 ## 7 Algerian Male 4 70052 El Hadi Jaz… Algerian,… 1970 ## 8 American Female 1097 10 Irene Arons… American,… 1918 ## 9 American Female 1097 21 Ruth Asawa American,… 1926 ## 10 American Female 1097 31 Dana Atchley American,… 1941 ## # … with 15,147 more rows, and 3 more variables: EndDate \u0026lt;dbl\u0026gt;, Wiki QID \u0026lt;chr\u0026gt;, ## # ULAN \u0026lt;dbl\u0026gt; Is it helpful? I think this is a useful preliminary data exploration function. It is a way to identify overall duplicate rows that might need to be further explored. It is also useful if you have particular variables you want to assess for duplicate rows either alone or in combination. For example it would be useful to look for duplicate medical records in a large dataset or multiple observations on a study participant in a single year. Its got an easy to remember name and is useful way to do initial assessment on data, but isn’t something that I would use regularly.\n","date":1644364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"174340d2c4ef0dc163b3d4df6642ff9f","permalink":"https://sph-r-programming-2023.netlify.app/functions/janitor_get_dupes/","publishdate":"2022-02-09T00:00:00Z","relpermalink":"/functions/janitor_get_dupes/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: get_dupes () Function of the Week: get_dupes () Becky 2022-02-09 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing For this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.","tags":null,"title":"janitor::get_dupes()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: tidyr::extract() Function of the Week: tidyr::extract() Shauna Rakshe 2022-02-09 tidyr:: extract() In this document, I will introduce the tidyr::extract() function and show what it’s for.\n#load libraries up library(tidyverse) ## Warning: package \u0026#39;tidyverse\u0026#39; was built under R version 4.0.5 ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.1.4 v stringr 1.4.0 ## v readr 2.1.1 v forcats 0.5.1 ## Warning: package \u0026#39;ggplot2\u0026#39; was built under R version 4.0.5 ## Warning: package \u0026#39;tibble\u0026#39; was built under R version 4.0.5 ## Warning: package \u0026#39;tidyr\u0026#39; was built under R version 4.0.5 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.0.5 ## Warning: package \u0026#39;purrr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;dplyr\u0026#39; was built under R version 4.0.5 ## Warning: package \u0026#39;stringr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;forcats\u0026#39; was built under R version 4.0.5 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() #extract() is in tidyr; this package is loaded by tidyverse #example dataset is \u0026#39;sentences\u0026#39; from stringr; this package is loaded by tidyverse What is it for? extract() will match portions (“capturing groups”) of character strings in a column using regular expressions, and put the groups into new columns. If there’s no match or the input is NA, extract() will output NA.\nThe basic syntax is: df %\u0026gt;% extract(character_column, c(“Group1_name”, “Group2_name”), “(regex expression for Group1)(regex expression for Group2)”)\n#Example 1: A simple example to see the syntax df \u0026lt;- data.frame(x = c(NA, \u0026quot;a-b\u0026quot;, \u0026quot;a-d\u0026quot;, \u0026quot;b-c\u0026quot;, \u0026quot;e-e\u0026quot;)) df ## x ## 1 \u0026lt;NA\u0026gt; ## 2 a-b ## 3 a-d ## 4 b-c ## 5 e-e #extract the letter(s)/number(s) before and after the dash into \u0026quot;A\u0026quot; and \u0026quot;B\u0026quot; variables, respectively #\u0026quot;[[:alnum:]]+\u0026quot; matches at least one alphanumeric character df %\u0026gt;% extract(x, c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;), \u0026quot;([[:alnum:]]+)-([[:alnum:]]+)\u0026quot;) ## A B ## 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 2 a b ## 3 a d ## 4 b c ## 5 e e # If no match, NA: #note that \u0026quot;[a-d]+\u0026quot; matches at least one a,b,c or d #this regular expression doesn\u0026#39;t match anything in the last row of df, so returns NA df %\u0026gt;% extract(x, c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;), \u0026quot;([a-d]+)-([a-d]+)\u0026quot;) ## A B ## 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 2 a b ## 3 a d ## 4 b c ## 5 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; #Example 2: the Harvard Sentences (stringr::sentences) are \u0026quot;phonetically balanced\u0026quot; statements that are used to test audio systems, because they contain all the sounds heard in everyday language. # for more information see ?sentences length(sentences) ## [1] 720 head(sentences, 10) ## [1] \u0026quot;The birch canoe slid on the smooth planks.\u0026quot; ## [2] \u0026quot;Glue the sheet to the dark blue background.\u0026quot; ## [3] \u0026quot;It\u0026#39;s easy to tell the depth of a well.\u0026quot; ## [4] \u0026quot;These days a chicken leg is a rare dish.\u0026quot; ## [5] \u0026quot;Rice is often served in round bowls.\u0026quot; ## [6] \u0026quot;The juice of lemons makes fine punch.\u0026quot; ## [7] \u0026quot;The box was thrown beside the parked truck.\u0026quot; ## [8] \u0026quot;The hogs were fed chopped corn and garbage.\u0026quot; ## [9] \u0026quot;Four hours of steady work faced us.\u0026quot; ## [10] \u0026quot;Large size in stockings is hard to sell.\u0026quot; What if we want to try to pluck out some nouns? One way is to look for all the words that follow “a” or “the”. This is going to give us a lot of adjectives too, but it’s a way to start.\n#make a tibble out of the sentences and then extract tibble(sentence = sentences) %\u0026gt;% extract(sentence, c(\u0026quot;article\u0026quot;, \u0026quot;noun\u0026quot;), \u0026quot;(a|the) ([^ ]+)\u0026quot;, remove = FALSE) ## # A tibble: 720 x 3 ## sentence article noun ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 The birch canoe slid on the smooth planks. the smooth ## 2 Glue the sheet to the dark blue background. the sheet ## 3 It\u0026#39;s easy to tell the depth of a well. the depth ## 4 These days a chicken leg is a rare dish. a chicken ## 5 Rice is often served in round bowls. \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 6 The juice of lemons makes fine punch. \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 7 The box was thrown beside the parked truck. the parked ## 8 The hogs were fed chopped corn and garbage. \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 9 Four hours of steady work faced us. \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## 10 Large size in stockings is hard to sell. \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## # ... with 710 more rows What if we want to find all the nouns that have color adjectives? Let’s find colors in the sentences and pluck out the color and the word after the color.\n#make a list of color names and turn it into a single regular expression colors \u0026lt;- c(\u0026quot;red\u0026quot;, \u0026quot;orange\u0026quot;, \u0026quot;yellow\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;purple\u0026quot;) color_match \u0026lt;- str_c(colors, collapse = \u0026quot;|\u0026quot;) color_match ## [1] \u0026quot;red|orange|yellow|green|blue|purple\u0026quot; #select sentences that contain a color has_color \u0026lt;- str_subset(sentences, color_match) length(has_color) ## [1] 57 head(has_color, 10) ## [1] \u0026quot;Glue the sheet to the dark blue background.\u0026quot; ## [2] \u0026quot;Two blue fish swam in the tank.\u0026quot; ## [3] \u0026quot;The colt reared and threw the tall rider.\u0026quot; ## [4] \u0026quot;The wide road shimmered in the hot sun.\u0026quot; ## [5] \u0026quot;See the cat glaring at the scared mouse.\u0026quot; ## [6] \u0026quot;A wisp of cloud hung in the blue air.\u0026quot; ## [7] \u0026quot;Leaves turn brown and yellow in the fall.\u0026quot; ## [8] \u0026quot;He ordered peach pie with ice cream.\u0026quot; ## [9] \u0026quot;Pure bred poodles have curls.\u0026quot; ## [10] \u0026quot;The spot on the blotter was made by green ink.\u0026quot; #extract the color and the word after the color. color_matches \u0026lt;- tibble(sentence = sentences) %\u0026gt;% extract(sentence, c(\u0026quot;color\u0026quot;, \u0026quot;noun\u0026quot;), \u0026quot;(red|orange|yellow|green|blue|purple) ([^ ]+)\u0026quot;, remove = FALSE) #drop all the empty rows. You can see we pulled out words like \u0026quot;shimmered\u0026quot; and \u0026quot;scared\u0026quot;, too! color_matches \u0026lt;- color_matches %\u0026gt;% drop_na() head(color_matches, 10) ## # A tibble: 10 x 3 ## sentence color noun ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Glue the sheet to the dark blue background. blue background. ## 2 Two blue fish swam in the tank. blue fish ## 3 The colt reared and threw the tall rider. red and ## 4 The wide road shimmered in the hot sun. red in ## 5 See the cat glaring at the scared mouse. red mouse. ## 6 A wisp of cloud hung in the blue air. blue air. ## 7 Leaves turn brown and yellow in the fall. yellow in ## 8 He ordered peach pie with ice cream. red peach ## 9 Pure bred poodles have curls. red poodles ## 10 The spot on the blotter was made by green ink. green ink. #we can get rid of the words accidentally matching \u0026quot;red\u0026quot; by tweaking the regex: #now we require a space before the \u0026quot;red\u0026quot; so we don\u0026#39;t get portions of words color_matches \u0026lt;- tibble(sentence = sentences) %\u0026gt;% extract(sentence, c(\u0026quot;color\u0026quot;, \u0026quot;noun\u0026quot;), \u0026quot;([ ]red|orange|yellow|green|blue|purple) ([^ ]+)\u0026quot;, remove = FALSE) color_matches \u0026lt;- color_matches %\u0026gt;% drop_na() color_matches ## # A tibble: 24 x 3 ## sentence color noun ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Glue the sheet to the dark blue background. \u0026quot;blue\u0026quot; background. ## 2 Two blue fish swam in the tank. \u0026quot;blue\u0026quot; fish ## 3 A wisp of cloud hung in the blue air. \u0026quot;blue\u0026quot; air. ## 4 Leaves turn brown and yellow in the fall. \u0026quot;yellow\u0026quot; in ## 5 The spot on the blotter was made by green ink. \u0026quot;green\u0026quot; ink. ## 6 The sofa cushion is red and of light weight. \u0026quot; red\u0026quot; and ## 7 A blue crane is a tall wading bird. \u0026quot;blue\u0026quot; crane ## 8 It is hard to erase blue or red ink. \u0026quot;blue\u0026quot; or ## 9 The lamp shone with a steady green flame. \u0026quot;green\u0026quot; flame. ## 10 The box is held by a bright red snapper. \u0026quot; red\u0026quot; snapper. ## # ... with 14 more rows #Note that extract() only returns the first match in a string! In this example, if there is a sentence with two colors, extract() will return only the first color and following word. #example: \u0026quot;It is hard to erase blue or red ink.\u0026quot; returns only \u0026quot;blue\u0026quot; \u0026quot;or\u0026quot; How could this be useful?\n#what if we have some super messy data? Multiple observations combined into one column, with no spaces in between so you can\u0026#39;t use separate()? messy_data \u0026lt;- tribble(~name, ~x1, ~x2, \u0026quot;Soniedensis SO0141abcefff\u0026quot;, 2.54, 5.784, \u0026quot;Vcholerae VC1124kjelsls\u0026quot;, 2.13, 6.534, \u0026quot;Dethogenes DH09483nannnowb\u0026quot;, 3.24, 8.74) messy_data %\u0026gt;% extract(name, c(\u0026quot;organism\u0026quot;, \u0026quot;abbrev\u0026quot;, \u0026quot;gene_num\u0026quot;, \u0026quot;letters\u0026quot;), \u0026quot;([A-Z][a-z]*) ([A-Z]+)([0-9]*)([a-z]+)\u0026quot;, remove = FALSE) ## # A tibble: 3 x 7 ## name organism abbrev gene_num letters x1 x2 ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Soniedensis SO0141abcefff Soniedensis SO 0141 abcefff 2.54 5.78 ## 2 Vcholerae VC1124kjelsls Vcholerae VC 1124 kjelsls 2.13 6.53 ## 3 Dethogenes DH09483nannnowb Dethogenes DH 09483 nannnowb 3.24 8.74 #another way to extract the same thing messy_data %\u0026gt;% extract(name, c(\u0026quot;organism\u0026quot;, \u0026quot;abbrev\u0026quot;, \u0026quot;gene_num\u0026quot;, \u0026quot;letters\u0026quot;), \u0026quot;([[:upper:]][[:lower:]]*) ([[:upper:]]+)([[:digit:]]*)([[:lower:]]+)\u0026quot;, remove = FALSE) ## # A tibble: 3 x 7 ## name organism abbrev gene_num letters x1 x2 ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Soniedensis SO0141abcefff Soniedensis SO 0141 abcefff 2.54 5.78 ## 2 Vcholerae VC1124kjelsls Vcholerae VC 1124 kjelsls 2.13 6.53 ## 3 Dethogenes DH09483nannnowb Dethogenes DH 09483 nannnowb 3.24 8.74 Is it helpful? I think that if I needed to distribute one character variable into several (for instance, if several observations were combined into one column), I would usually prefer to use a function like separate(). Human-entered data often has spaces or symbols between observations, which makes using separate() easy. However, computer output can be a single very long character string. I can see how using extract() to pluck out relevant information (say, timestamps or ID numbers) from a column of long strings could save a lot of time!\n","date":1644364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"801e562e87dc00f4c7b6a048f74fb996","permalink":"https://sph-r-programming-2023.netlify.app/functions/tidyr_extract/","publishdate":"2022-02-09T00:00:00Z","relpermalink":"/functions/tidyr_extract/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: tidyr::extract() Function of the Week: tidyr::extract() Shauna Rakshe 2022-02-09 tidyr:: extract() In this document, I will introduce the tidyr::extract() function and show what it’s for. #load libraries up library(tidyverse) ## Warning: package \u0026#39;tidyverse\u0026#39; was built under R version 4.0.5 ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.","tags":null,"title":"tidyr::extract()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: dplyr::ntile() Function of the Week: dplyr::ntile() Qijia Liu 2022-01-26 In this document, I will introduce the ntile() function and show what it’s for. library(dplyr) library(tidyverse) library(tidytuesdayR) tuesdata \u0026lt;- tt_load(\u0026#39;2022-01-18\u0026#39;) ChocolateBar \u0026lt;- tuesdata$chocolate What is it for? The ntile() function can divide the observations into specified number of roughly equal sized groups by sorting the variable of interest with ascending order and then split up into. It requires two arguments as input: a vector(i.e. x) and an integer(i.e. 4).\nExamples vector \u0026lt;- rep(c(-1,1,2), each=4) vector ## [1] -1 -1 -1 -1 1 1 1 1 2 2 2 2 ntile(vector, 2) ## [1] 1 1 1 1 1 1 2 2 2 2 2 2 vector \u0026lt;- rep(c(2,-1,1), each=4) vector ## [1] 2 2 2 2 -1 -1 -1 -1 1 1 1 1 ntile(vector, 2) ## [1] 2 2 2 2 1 1 1 1 1 1 2 2 Chocolate Bar: 1. Divide the rating within a country into four ranked groups # How many countries? n_distinct(ChocolateBar$company_location) ## [1] 67 # Only select countries start with \u0026quot;A\u0026quot;: ChocolateBar \u0026lt;- ChocolateBar %\u0026gt;% select(company_location, rating) %\u0026gt;% filter(str_detect(company_location, \u0026quot;^A\u0026quot;)) table(ChocolateBar$company_location) ## ## Amsterdam Argentina Australia Austria ## 12 9 53 30 ChocolateBar \u0026lt;- ChocolateBar %\u0026gt;% mutate(quantile_rating = ntile(rating, 4)) table(ChocolateBar$quantile_rating) ## ## 1 2 3 4 ## 26 26 26 26 dim(ChocolateBar) ## [1] 104 3 2. Divide the rating within a country into four ranked groups by_ChocolateBar_quartile \u0026lt;- ChocolateBar %\u0026gt;% group_by(company_location) %\u0026gt;% mutate(quantile_company_location = ntile(rating, 4)) table(by_ChocolateBar_quartile$company_location, by_ChocolateBar_quartile$quantile_company_location) ## ## 1 2 3 4 ## Amsterdam 3 3 3 3 ## Argentina 3 2 2 2 ## Australia 14 13 13 13 ## Austria 8 8 7 7 3. Filter ChocolateBar according to rating median median(ChocolateBar$rating) ## [1] 3.25 range(ChocolateBar$rating) ## [1] 2.5 4.0 #only keep the observations less than the median ChocolateBar \u0026lt;- filter(ChocolateBar, ntile(rating, 2) \u0026lt; 2) range(ChocolateBar$rating) ## [1] 2.50 3.25 dim(ChocolateBar) ## [1] 52 3 Is it helpful? It is very useful when we categorize continuous predictor variables. Other function like cut() could perform data binning as well. ","date":1643155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"a21afc67b89388bec6d672a969ae64fd","permalink":"https://sph-r-programming-2023.netlify.app/functions/dplyr_ntile/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/functions/dplyr_ntile/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: dplyr::ntile() Function of the Week: dplyr::ntile() Qijia Liu 2022-01-26 In this document, I will introduce the ntile() function and show what it’s for. library(dplyr) library(tidyverse) library(tidytuesdayR) tuesdata \u0026lt;- tt_load(\u0026#39;2022-01-18\u0026#39;) ChocolateBar \u0026lt;- tuesdata$chocolate What is it for? The ntile() function can divide the observations into specified number of roughly equal sized groups by sorting the variable of interest with ascending order and then split up into.","tags":null,"title":"dplyr::ntile()","type":"docs"},{"authors":null,"categories":null,"content":" Required Data Transformation (5.1-5.5) from R for Data Science ggplot2: Elegant Graphics for Data Analysis, Scales \u0026amp; Guides R for Data Science: Factors - we will continue to work with factors in the next few classes with forcats examples like provided here. Optional Tidyverse style guide Advanced R: style guide This column-wise operations vignette will be useful for the next couple classes. ","date":1643155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"13bbf5064f8e7d91a62ab29bec4d6a2c","permalink":"https://sph-r-programming-2023.netlify.app/reading/04-reading/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/reading/04-reading/","section":"reading","summary":" Required Data Transformation (5.1-5.5) from R for Data Science ggplot2: Elegant Graphics for Data Analysis, Scales \u0026amp; Guides R for Data Science: Factors - we will continue to work with factors in the next few classes with forcats examples like provided here. Optional Tidyverse style guide Advanced R: style guide This column-wise operations vignette will be useful for the next couple classes. ","tags":null,"title":"Part 4. `dplyr`: `mutate()`, `across()`, ggplot: faceting, scales","type":"docs"},{"authors":null,"categories":null,"content":" Required Data Transformation (5.6-5.7) from R for Data Science Aggregating data with summarize and map - we will cover map() and rowwise() later, but summarize and mutate with across are described here. You may want to re-visit this when we get to purrr. Optional This column-wise operations vignette will be useful for the next couple classes. The following resources are optional reading, but quite helpful in your RMarkdown Journey.\nRMarkdown Cheatsheet RMarkdown Cookbook RMarkdown for Scientists ","date":1643155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"b547b9730ab3fca37d31e6ff09ab3c92","permalink":"https://sph-r-programming-2023.netlify.app/reading/05-reading/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/reading/05-reading/","section":"reading","summary":"Required Data Transformation (5.6-5.7) from R for Data Science Aggregating data with summarize and map - we will cover map() and rowwise() later, but summarize and mutate with across are described here. You may want to re-visit this when we get to purrr. Optional This column-wise operations vignette will be useful for the next couple classes. The following resources are optional reading, but quite helpful in your RMarkdown Journey.","tags":null,"title":"Part 5. summarize() and group_by(), doing things with multiple tables (left_join() etc), reshaping data (i.e. pivot_longer())","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: fct_collapse() Function of the Week: fct_collapse() Libby White Last Updated 2022-01-24 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing\nFor this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.\nfct_collapse() In this document, I will introduce the fct_collapse() function and show what it’s for. #load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() #example dataset library(palmerpenguins) What is it for? This function is used for re-factoring a factor or character variable into fewer factor levels than it currently has. For example, I changed the factor variable “island” in the penguins data set from 3 levels to 2 by combining the islands “Dream” and “Torgersen” into “Not_Boscoe” below: # 3 Factor Levels table(penguins$island) ## ## Biscoe Dream Torgersen ## 168 124 52 # 2 Factor Levels penguins_refactored \u0026lt;- fct_collapse(penguins$island, Biscoe = \u0026quot;Biscoe\u0026quot;, Not_Biscoe = c(\u0026quot;Torgersen\u0026quot;, \u0026quot;Dream\u0026quot;), other_level = \u0026quot;Missing\u0026quot;) # If any other values are encountered, they # will be classified as \u0026quot;Missing\u0026quot; table(penguins_refactored) ## penguins_refactored ## Biscoe Not_Biscoe ## 168 176 As a second example, I re-factored the variable for number of cylinders (“cyl”) from the mtcars data set from 3 to 2 factor levels: CARS \u0026lt;- mtcars CARS$cyl \u0026lt;- as.factor(CARS$cyl) # 3 Factor Levels table(CARS$cyl) ## ## 4 6 8 ## 11 7 14 # 2 Factor Levels CARS_refactored \u0026lt;- fct_collapse(CARS$cyl, Four = \u0026quot;4\u0026quot;, More_than_Four = c(\u0026quot;6\u0026quot;, \u0026quot;8\u0026quot;), other_level = \u0026quot;Missing\u0026quot;) table(CARS_refactored) ## CARS_refactored ## Four More_than_Four ## 11 21 Is it helpful? This function has its uses, but, overall, I think it may just be easier to create a new variable with the desired factor levels using mutate() and either case_when() or ifelse(). Below is an example of what I would do instead: penguins_refactored_2 \u0026lt;- penguins %\u0026gt;% mutate(island_2lvls = ifelse(island == \u0026quot;Biscoe\u0026quot;, \u0026quot;Biscoe\u0026quot;, \u0026quot;Not Biscoe\u0026quot;)) table(penguins_refactored_2$island_2lvls) ## ## Biscoe Not Biscoe ## 168 176 Using the second example with the mtcars data set, I would do the following: CARS_refactored_2 \u0026lt;- CARS %\u0026gt;% mutate(cyl_2lvls = ifelse(cyl == \u0026quot;4\u0026quot;, \u0026quot;Four\u0026quot;, \u0026quot;More than four\u0026quot;)) table(CARS_refactored_2$cyl_2lvls) ## ## Four More than four ## 11 21 ","date":1642982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"d625018ac9ac9271523ebbb1b2f617e0","permalink":"https://sph-r-programming-2023.netlify.app/functions/forcats_fct_collapse/","publishdate":"2022-01-24T00:00:00Z","relpermalink":"/functions/forcats_fct_collapse/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: fct_collapse() Function of the Week: fct_collapse() Libby White Last Updated 2022-01-24 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing For this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.","tags":null,"title":"forcats::fct_collapse()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Geom_Density Function of the Week: Geom_Density Mary McDonnell 2021_01_17 Geom_Density Geom_density is a function within the ggplot2 package that is used to plot/visualize data. It is a commonly used tool in statistics to display the distribution of numerical data; it does so by plotting the estimated kernel density, resulting in the smoothing/normalizing the distribution of the data.\n#load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() #example dataset library(palmerpenguins) data(penguins) What is it for? Discuss what the function does. Learn from the examples, but show how to use it using another dataset such as penguins. If you can provide two examples, even better!\nOne of the most simple/classic means of displaying the distribution of data is with a histogram. The histogram below shows that the distribution of data (of the body mass of the penguins) are skewed to the right, and that there are a few outlier datapoints present.\nggplot(penguins, aes(x=body_mass_g)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 2 rows containing non-finite values (stat_bin). The function Geom_Density removes outlier data points, and acts to visualize the distribution of the data by smoothing it out– it helps to display where the datapoints/values are concentrated amongst the distribution in the form of peaks (see below).\nggplot(penguins, aes(x=body_mass_g)) + geom_density() ## Warning: Removed 2 rows containing non-finite values (stat_density). Is it helpful? Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\nGeom_density smooths the distribution of the data through the removal of outlier data points and displays the data in a continuous smooth distribution. This function acts to simplify how the data are represented in case the distribution is bimodal, which sometimes cannot be easily determined with as much definition in a histogram.\n","date":1642550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"c7a808c68b91d903258877adc44fcc31","permalink":"https://sph-r-programming-2023.netlify.app/functions/ggplot2_geom_density/","publishdate":"2022-01-19T00:00:00Z","relpermalink":"/functions/ggplot2_geom_density/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Geom_Density Function of the Week: Geom_Density Mary McDonnell 2021_01_17 Geom_Density Geom_density is a function within the ggplot2 package that is used to plot/visualize data. It is a commonly used tool in statistics to display the distribution of numerical data; it does so by plotting the estimated kernel density, resulting in the smoothing/normalizing the distribution of the data. #load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.","tags":null,"title":"ggplot2::geom_density()","type":"docs"},{"authors":null,"categories":null,"content":" Required ggplot2 ggplot2 BERD workshop slides - lots more on different geoms and how to customize plots dplyr dplyr cheatsheet - one of the best references. Combining functions using the pipe operator, %\u0026gt;% - if you’re confused about %\u0026gt;%, please read this. Optional Customizing ggplot2 If you are interested in learning more about ggplot:\nThemes to improve your ggplot figures by David Keyes is really helpful for learning how to do more styling. RStudio also publishes a ggplot cheat sheet that is really handy! Customizing ggplot2 Cheatsheet is also handy, because it organizes ggplot2 commands by task. Documentation for all ggplot features is available here. Using tidyselect (Intermediate Level) Remember, select() works on columns.\ntidyselect lets you select columns by matching names. In conjunction with the across() command, you can apply the same operation to multiple columns at once. This is especially handy when you need to produce a summary on all numeric columns.\nYou can run the tidyselect tutorial by first installing the tidyowl package by Ted Laderas:\ninstall.packages(\u0026quot;remotes\u0026quot;) remotes::install_github(\u0026quot;laderast/tidyowl\u0026quot;) and then running this code in your Rstudio console window:\nlibrary(tidyowl) learn_tidyselect() ","date":1642550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"39100b29a777d527fde18e1fccc18a57","permalink":"https://sph-r-programming-2023.netlify.app/reading/03-reading/","publishdate":"2022-01-19T00:00:00Z","relpermalink":"/reading/03-reading/","section":"reading","summary":"Required ggplot2 ggplot2 BERD workshop slides - lots more on different geoms and how to customize plots dplyr dplyr cheatsheet - one of the best references. Combining functions using the pipe operator, %\u0026gt;% - if you’re confused about %\u0026gt;%, please read this. Optional Customizing ggplot2 If you are interested in learning more about ggplot:\nThemes to improve your ggplot figures by David Keyes is really helpful for learning how to do more styling.","tags":null,"title":"Part 3: `ggplot2`, factors, boxplots, `dplyr`: subsetting using `filter()`/`select()`","type":"docs"},{"authors":null,"categories":null,"content":" Required Data Organization in Spreadsheets by Kara Woo and Karl Broman - if there is one paper that I think is useful for everyone, it’s this one. Absolute and Relative File Paths - sometimes understanding file paths can be difficult. This is a great follow up reading. The video is very helpful as well. What are R packages? ","date":1641945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"def8daf7a7859ddd197971151353ea19","permalink":"https://sph-r-programming-2023.netlify.app/reading/02-reading/","publishdate":"2022-01-12T00:00:00Z","relpermalink":"/reading/02-reading/","section":"reading","summary":" Required Data Organization in Spreadsheets by Kara Woo and Karl Broman - if there is one paper that I think is useful for everyone, it’s this one. Absolute and Relative File Paths - sometimes understanding file paths can be difficult. This is a great follow up reading. The video is very helpful as well. What are R packages? ","tags":null,"title":"Part 2: Data Frames/Loading Data/ggplot2","type":"docs"},{"authors":null,"categories":null,"content":" Ted Laderas In this document, I will introduce the slice() function and show what it’s for.\nlibrary(tidyverse) ## Warning: package \u0026#39;tidyverse\u0026#39; was built under R version 4.0.3 ## -- Attaching packages --------------------------------------- tidyverse 1.3.0 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.0.6 v dplyr 1.0.4 ## v tidyr 1.1.2 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## Warning: package \u0026#39;ggplot2\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;tibble\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;tidyr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;readr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;purrr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;dplyr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;stringr\u0026#39; was built under R version 4.0.3 ## Warning: package \u0026#39;forcats\u0026#39; was built under R version 4.0.3 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(palmerpenguins) ## Warning: package \u0026#39;palmerpenguins\u0026#39; was built under R version 4.0.3 data(penguins) What is it for? Say you want the first 7 rows of a table. Well, slice() is an easy way to do that. The slice() function accepts two arguments: The first is the dataset, and the second is the range of values you want to extract.\nslice(penguins, 1:7) ## # A tibble: 7 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_~ body_mass_g sex ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; ## 1 Adelie Torge~ 39.1 18.7 181 3750 male ## 2 Adelie Torge~ 39.5 17.4 186 3800 fema~ ## 3 Adelie Torge~ 40.3 18 195 3250 fema~ ## 4 Adelie Torge~ NA NA NA NA \u0026lt;NA\u0026gt; ## 5 Adelie Torge~ 36.7 19.3 193 3450 fema~ ## 6 Adelie Torge~ 39.3 20.6 190 3650 male ## 7 Adelie Torge~ 38.9 17.8 181 3625 fema~ ## # ... with 1 more variable: year \u0026lt;int\u0026gt; slice() is much more helpful in a tidy workflow, so you can see the first few rows of the data when you’re processing. This is really helpful when you’re building up a pipeline and need to show intermediate output without showing the entire table.\npenguins %\u0026gt;% slice(1:7) ## # A tibble: 7 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_~ body_mass_g sex ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; ## 1 Adelie Torge~ 39.1 18.7 181 3750 male ## 2 Adelie Torge~ 39.5 17.4 186 3800 fema~ ## 3 Adelie Torge~ 40.3 18 195 3250 fema~ ## 4 Adelie Torge~ NA NA NA NA \u0026lt;NA\u0026gt; ## 5 Adelie Torge~ 36.7 19.3 193 3450 fema~ ## 6 Adelie Torge~ 39.3 20.6 190 3650 male ## 7 Adelie Torge~ 38.9 17.8 181 3625 fema~ ## # ... with 1 more variable: year \u0026lt;int\u0026gt; Is it helpful? Yes, when you need to just show part of a table as an example, slice() can come in handy. I don’t use it everyday, but it can come in handy.\n","date":1610496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"3fd570c5fadc8ea64a910781fe38a251","permalink":"https://sph-r-programming-2023.netlify.app/functions/slice/","publishdate":"2021-01-13T00:00:00Z","relpermalink":"/functions/slice/","section":"functions","summary":"Ted Laderas In this document, I will introduce the slice() function and show what it’s for.\nlibrary(tidyverse) ## Warning: package \u0026#39;tidyverse\u0026#39; was built under R version 4.0.3 ## -- Attaching packages --------------------------------------- tidyverse 1.3.0 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.0.6 v dplyr 1.0.4 ## v tidyr 1.1.2 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## Warning: package \u0026#39;ggplot2\u0026#39; was built under R version 4.","tags":null,"title":"dplyr::slice()","type":"docs"},{"authors":null,"categories":null,"content":" Required Introduction to broom Suggested Programming with dplyr - in case I can’t get to tidyeval use for functions with tidyverse ggplot2 in packages - examples how to use ggplot inside functions Resources for learning more statistics: Modern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/ Danielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/ More on using map and nested data with modeling: R for Data Science: Many Models broom and dplyr Useful vignettes on table output: gtsummary intro to tbl_summary Ted Laderas’s interactive workbook on learning rowwise and nested data: learning rowwise We might not get to dates but in case you want to learn more: Dates and times in R for Data Science If you want to learn about tidymodels: Introduction to Machine Learning with the Tidyverse Joy of Functional programming talk by Hadley Wickham - more on nesting/iteration More on model building and machine learning Model Building from R for Data Science Many Models - from R for Data science. Covers group_by()/nest() and list-columns Tidymodels with R: Recipes Tidymodels with R: Fitting Models with Parsnip Tidymodels with R: Judging Model Effectiveness UMAP and Cocktail Recipes Tidymodels: K-means PCA and Penguins ","date":1583798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"d0380f92d2c5810a9015341ca52e98e8","permalink":"https://sph-r-programming-2023.netlify.app/reading/10-reading/","publishdate":"2020-03-10T00:00:00Z","relpermalink":"/reading/10-reading/","section":"reading","summary":"Required Introduction to broom Suggested Programming with dplyr - in case I can’t get to tidyeval use for functions with tidyverse ggplot2 in packages - examples how to use ggplot inside functions Resources for learning more statistics: Modern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/ Danielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.","tags":null,"title":"Part 9 (Class 10-11) More stats, broom, and tables (gt, gtsummary)","type":"docs"},{"authors":null,"categories":null,"content":" Required Introduction to map() - Jenny Bryan Purrr Tips and Tricks by Emil Hvitfeldt. Suggested More on using map and nested data with modeling: R for Data Science: Many Models broom and dplyr Joy of Functional programming talk by Hadley Wickham - more on nesting/iteration For learning more about statistics with R:\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.com/ Danielle Navarro’s Learning Statistics with R is excellent and talks much more about statistics: https://learningstatisticswithr.com/ Model Basics from R for Data Science More on survival analysis in R Survival Analysis in R Tutorial by Dr. Emily C Zabor Survminer survival plot vignette UVA’s Survival Workshop materials Rview’s Survival Analysis ","date":1583193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"efc0eb1097e131916a05aba545a0a59a","permalink":"https://sph-r-programming-2023.netlify.app/reading/09-reading/","publishdate":"2020-03-03T00:00:00Z","relpermalink":"/reading/09-reading/","section":"reading","summary":"Required Introduction to map() - Jenny Bryan Purrr Tips and Tricks by Emil Hvitfeldt. Suggested More on using map and nested data with modeling: R for Data Science: Many Models broom and dplyr Joy of Functional programming talk by Hadley Wickham - more on nesting/iteration For learning more about statistics with R:\nModern Dive / Statistical Inference via Data Science by Chester Ismay and Albert Y Kim is a nice place to start: https://moderndive.","tags":null,"title":"Part 8 (Class 9). Intro to stats/broom/More Purrr","type":"docs"},{"authors":null,"categories":null,"content":" Required Introduction to Functions and Arguments Introduction to Lists - be sure to read this before class next week. Control your Factors Using Forcats Suggested More on joining data in Relational data from R for Data Science, especially about duplicate keys Dates and times in R for Data Science ","date":1581292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"8d8807fc9147f1179507cdb58c8cc00b","permalink":"https://sph-r-programming-2023.netlify.app/reading/06-reading/","publishdate":"2020-02-10T00:00:00Z","relpermalink":"/reading/06-reading/","section":"reading","summary":" Required Introduction to Functions and Arguments Introduction to Lists - be sure to read this before class next week. Control your Factors Using Forcats Suggested More on joining data in Relational data from R for Data Science, especially about duplicate keys Dates and times in R for Data Science ","tags":null,"title":"Part 6. Lists and RMarkdown","type":"docs"},{"authors":null,"categories":null,"content":" Updated March 22, 2022.\nThis course was heavily based on Dr. Ted Laderas’ version that we collaboratively developed for Winter 2021, and which was originally based on his Ready for R Course. These reviews are also a reflection of all his hard work.\nBelow are some selected reviews and comments from students in the course. They are anonymous.\nThank you for the overall pacing and information that you covered during this class. I feel like I now have a basic and maybe slightly intermediate knowledge for R.\nI loved the stats smorgasbord in the last couple classes. It’s a lot of info and I’m going to have to go back over the notes to absorb it, but I really appreciate being shown even a glimpse of useful stuff – I feel like so often, half the battle is just knowing that you can do something. If you know it exists, you can find the name and figure out how to do it! Thank you so much for a wonderful class. I wish there was a part 2 for more advanced R. This class made my other classes so much easier and I’m sure I will be fervently wishing you thanks for years!\nI’m sad that this class is ending. Thank you so much for the excellent teaching and the many very helpful tips and tricks! And thanks for encouraging us with regard to programming – R and other programming languages can feel really intimidating to those of us who don’t have a lot of comp sci background, and I really appreciated how friendly and accessible you made everything.\nI really love this class! I will try to pester someone to see if this class can ever be a prereq for the biostats program in undergrad because this has saved me so much\nThanks so much for a wonderful class this term. I learned a lot\nThank you for your help and for all of the great tips in helping to master R!\nThis class was so wonderfully helpful. Thank you so much!\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"c94171b29fd78895e874028f7926ba7d","permalink":"https://sph-r-programming-2023.netlify.app/reviews/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviews/","section":"","summary":"Updated March 22, 2022.\nThis course was heavily based on Dr. Ted Laderas’ version that we collaboratively developed for Winter 2021, and which was originally based on his Ready for R Course. These reviews are also a reflection of all his hard work.\nBelow are some selected reviews and comments from students in the course. They are anonymous.\nThank you for the overall pacing and information that you covered during this class.","tags":null,"title":"Course Reviews","type":"page"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Joseph W. Vera 2022-03-02 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing\nFor this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.\nFunction Name In this document, I will introduce the n_distict() function and show what it’s for.\n#load tidyverse up library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.1.4 v stringr 1.4.0 ## v readr 2.1.1 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(dplyr) What is it for? ?distinct ## starting httpd help server ... done #This function (n_distinct) does what the name suggests, it counts the number of unique values within a vector or variable. If you want to count in a basic way, you can see how n_distinct makes your code more efficient. data \u0026lt;- data.frame(x= c(1,1,2,2,2,3,3,4,5), group = c(\u0026quot;A\u0026quot;, \u0026quot;A\u0026quot;, \u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;)) data_count_1 \u0026lt;- aggregate(data = data, x ~ group, function(x) length(unique(x))) data_count_2 \u0026lt;- data %\u0026gt;% group_by(group) %\u0026gt;% summarise(count = n_distinct(x)) #However, you can also use n_distinct in parallel with other functions (e.g., filter or group_by). Let\u0026#39;s take a look at what exactly we are doing and how we\u0026#39;ve combined \u0026quot;n\u0026quot; and \u0026quot;distinct\u0026quot;. library(palmerpenguins) glimpse(penguins) ## Rows: 344 ## Columns: 8 ## $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel~ ## $ island \u0026lt;fct\u0026gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse~ ## $ bill_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ~ ## $ bill_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ~ ## $ flipper_length_mm \u0026lt;int\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186~ ## $ body_mass_g \u0026lt;int\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ~ ## $ sex \u0026lt;fct\u0026gt; male, female, female, NA, female, male, female, male~ ## $ year \u0026lt;int\u0026gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007~ penguins %\u0026gt;% distinct(species) ## # A tibble: 3 x 1 ## species ## \u0026lt;fct\u0026gt; ## 1 Adelie ## 2 Gentoo ## 3 Chinstrap #so we have 3 distinct species in this data set. but what if we want to know the number of different species on each island? penguins %\u0026gt;% group_by(island) %\u0026gt;% summarise(count = n_distinct(species)) ## # A tibble: 3 x 2 ## island count ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 Biscoe 2 ## 2 Dream 2 ## 3 Torgersen 1 #now lets say we want to know the number of unique values not only across species, but also across island and sex...we get to write it 3 times...inefficient! penguins %\u0026gt;% summarise(distinct_species = n_distinct(species), distinct_island = n_distinct(island), distinct_sex = n_distinct(sex)) ## # A tibble: 1 x 3 ## distinct_species distinct_island distinct_sex ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 3 3 3 #isn\u0026#39;t there a better way? penguins %\u0026gt;% summarise(across(c(species, island, sex), n_distinct)) ## # A tibble: 1 x 3 ## species island sex ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 3 3 3 #it is important to remember that \u0026quot;NA\u0026quot; can be considered a unique value, so how can we avoid that? In addition to telling R what variable you are counting the unique values for, you can also tell it to not count \u0026quot;NA\u0026quot; values. The default is \u0026quot;false\u0026quot; and thus na values are considered to be unique. penguins %\u0026gt;% summarise(count = n_distinct(sex, na.rm = TRUE)) ## # A tibble: 1 x 1 ## count ## \u0026lt;int\u0026gt; ## 1 2 Is it helpful? I think this function is a good way to add another glimpse of your data. Is it something that you will use by itself, more than likely not; however, I think it can help you double check your data. Are there “NA” values that you haven’t noticed? Did you accidentally create a unique value that you didn’t mean to? In the end this is still just a count function.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"6da3464506d1de9614d2192519fb5a53","permalink":"https://sph-r-programming-2023.netlify.app/functions/dplyr_n_distinct/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/dplyr_n_distinct/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Joseph W. Vera 2022-03-02 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing For this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.","tags":null,"title":"dplyr::n_distict()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: dplyr::pull() Function of the Week: dplyr::pull() Saffron Evergreen 2022-03-02 Function of the Week Submit both the .Rmd and the .html files.\nFunction: Pull() In this document, I will introduce the pull() function, which is within the tidyverse package. I will show what it’s for, what it does and doesn’t do.\nlibrary(tidyverse) library(palmerpenguins) data(penguins) print(head(penguins)) ## # A tibble: 6 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_~ body_mass_g sex ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; ## 1 Adelie Torge~ 39.1 18.7 181 3750 male ## 2 Adelie Torge~ 39.5 17.4 186 3800 fema~ ## 3 Adelie Torge~ 40.3 18 195 3250 fema~ ## 4 Adelie Torge~ NA NA NA NA \u0026lt;NA\u0026gt; ## 5 Adelie Torge~ 36.7 19.3 193 3450 fema~ ## 6 Adelie Torge~ 39.3 20.6 190 3650 male ## # ... with 1 more variable: year \u0026lt;int\u0026gt; What is it for? What this function does and how to apply it within the dataset ‘penguins’.\nThis is a function in tidyverse that you can use to extract columns.\nThe value that is created from using pull() is a vector, which prints in the same length (amount of values) as is in the data frame.\nExample 1: calling variable name pull(data, var name)\npull(penguins, species) ## [1] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [8] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [15] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [22] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [29] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [36] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [43] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [50] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [57] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [64] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [71] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [78] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [85] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [92] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [99] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [106] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [113] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [120] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [127] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [134] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [141] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [148] Adelie Adelie Adelie Adelie Adelie Gentoo Gentoo ## [155] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [162] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [169] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [176] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [183] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [190] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [197] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [204] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [211] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [218] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [225] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [232] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [239] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [246] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [253] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [260] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [267] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [274] Gentoo Gentoo Gentoo Chinstrap Chinstrap Chinstrap Chinstrap ## [281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [344] Chinstrap ## Levels: Adelie Chinstrap Gentoo # shows all values, shows the 3 levels of the factored variable at the very end Example 2: calling variable index, positive integer pull(data, var +#)\npull(penguins, 2) ## [1] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## [8] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## [15] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Biscoe ## [22] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [29] Biscoe Biscoe Dream Dream Dream Dream Dream ## [36] Dream Dream Dream Dream Dream Dream Dream ## [43] Dream Dream Dream Dream Dream Dream Dream ## [50] Dream Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [57] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [64] Biscoe Biscoe Biscoe Biscoe Biscoe Torgersen Torgersen ## [71] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## [78] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## [85] Dream Dream Dream Dream Dream Dream Dream ## [92] Dream Dream Dream Dream Dream Dream Dream ## [99] Dream Dream Biscoe Biscoe Biscoe Biscoe Biscoe ## [106] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [113] Biscoe Biscoe Biscoe Biscoe Torgersen Torgersen Torgersen ## [120] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## [127] Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Dream ## [134] Dream Dream Dream Dream Dream Dream Dream ## [141] Dream Dream Dream Dream Dream Dream Dream ## [148] Dream Dream Dream Dream Dream Biscoe Biscoe ## [155] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [162] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [169] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [176] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [183] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [190] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [197] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [204] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [211] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [218] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [225] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [232] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [239] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [246] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [253] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [260] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [267] Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## [274] Biscoe Biscoe Biscoe Dream Dream Dream Dream ## [281] Dream Dream Dream Dream Dream Dream Dream ## [288] Dream Dream Dream Dream Dream Dream Dream ## [295] Dream Dream Dream Dream Dream Dream Dream ## [302] Dream Dream Dream Dream Dream Dream Dream ## [309] Dream Dream Dream Dream Dream Dream Dream ## [316] Dream Dream Dream Dream Dream Dream Dream ## [323] Dream Dream Dream Dream Dream Dream Dream ## [330] Dream Dream Dream Dream Dream Dream Dream ## [337] Dream Dream Dream Dream Dream Dream Dream ## [344] Dream ## Levels: Biscoe Dream Torgersen # shows all values, shows the 3 levels of the factored variable at the very end Example 3: calling variable index, negative integer pull(data, var -#)\npull(penguins, -2) #2nd column from the right side ## [1] male female female \u0026lt;NA\u0026gt; female male female male \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ## [11] \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; female male male female female male female male ## [21] female male female male male female male female female male ## [31] female male female male female male male female female male ## [41] female male female male female male male \u0026lt;NA\u0026gt; female male ## [51] female male female male female male female male female male ## [61] female male female male female male female male female male ## [71] female male female male female male female male female male ## [81] female male female male female male male female male female ## [91] female male female male female male female male female male ## [101] female male female male female male female male female male ## [111] female male female male female male female male female male ## [121] female male female male female male female male female male ## [131] female male female male female male female male female male ## [141] female male female male female male male female female male ## [151] female male female male female male male female female male ## [161] female male female male female male female male female male ## [171] female male male female female male female male \u0026lt;NA\u0026gt; male ## [181] female male male female female male female male female male ## [191] female male female male female male male female female male ## [201] female male female male female male female male female male ## [211] female male female male female male female male \u0026lt;NA\u0026gt; male ## [221] female male female male male female female male female male ## [231] female male female male female male female male female male ## [241] female male female male female male female male male female ## [251] female male female male female male \u0026lt;NA\u0026gt; male female male ## [261] female male female male female male female male \u0026lt;NA\u0026gt; male ## [271] female \u0026lt;NA\u0026gt; female male female male female male male female ## [281] male female female male female male female male female male ## [291] female male male female female male female male female male ## [301] female male female male female male female male female male ## [311] male female female male female male male female male female ## [321] female male female male male female female male female male ## [331] female male female male male female male female female male ## [341] female male male female ## Levels: female male # shows all values, shows the 2 levels of the factored variable at the very end Example 4: using a pipe to save a value as a vector x1\u0026lt;- data %\u0026gt;% pull(column)\nbody_mass_vector \u0026lt;- penguins %\u0026gt;% pull(body_mass_g) body_mass_vector # shows all values from the dataframe ## [1] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400 ## [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950 ## [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000 ## [46] 4600 3425 2975 3450 4150 3500 4300 3450 4050 2900 3700 3550 3800 2850 3750 ## [61] 3150 4400 3600 4050 2850 3950 3350 4100 3050 4450 3600 3900 3550 4150 3700 ## [76] 4250 3700 3900 3550 4000 3200 4700 3800 4200 3350 3550 3800 3500 3950 3600 ## [91] 3550 4300 3400 4450 3300 4300 3700 4350 2900 4100 3725 4725 3075 4250 2925 ## [106] 3550 3750 3900 3175 4775 3825 4600 3200 4275 3900 4075 2900 3775 3350 3325 ## [121] 3150 3500 3450 3875 3050 4000 3275 4300 3050 4000 3325 3500 3500 4475 3425 ## [136] 3900 3175 3975 3400 4250 3400 3475 3050 3725 3000 3650 4250 3475 3450 3750 ## [151] 3700 4000 4500 5700 4450 5700 5400 4550 4800 5200 4400 5150 4650 5550 4650 ## [166] 5850 4200 5850 4150 6300 4800 5350 5700 5000 4400 5050 5000 5100 4100 5650 ## [181] 4600 5550 5250 4700 5050 6050 5150 5400 4950 5250 4350 5350 3950 5700 4300 ## [196] 4750 5550 4900 4200 5400 5100 5300 4850 5300 4400 5000 4900 5050 4300 5000 ## [211] 4450 5550 4200 5300 4400 5650 4700 5700 4650 5800 4700 5550 4750 5000 5100 ## [226] 5200 4700 5800 4600 6000 4750 5950 4625 5450 4725 5350 4750 5600 4600 5300 ## [241] 4875 5550 4950 5400 4750 5650 4850 5200 4925 4875 4625 5250 4850 5600 4975 ## [256] 5500 4725 5500 4700 5500 4575 5500 5000 5950 4650 5500 4375 5850 4875 6000 ## [271] 4925 NA 4850 5750 5200 5400 3500 3900 3650 3525 3725 3950 3250 3750 4150 ## [286] 3700 3800 3775 3700 4050 3575 4050 3300 3700 3450 4400 3600 3400 2900 3800 ## [301] 3300 4150 3400 3800 3700 4550 3200 4300 3350 4100 3600 3900 3850 4800 2700 ## [316] 4500 3950 3650 3550 3500 3675 4450 3400 4300 3250 3675 3325 3950 3600 4050 ## [331] 3350 3450 3250 4050 3800 3525 3950 3650 3650 4000 3400 3775 4100 3775 Example 5: pull more than 1 column at a time data %\u0026gt;% pull(column [dbl], column [chr])\npenguins %\u0026gt;% pull(body_mass_g, island) ## Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## 3750 3800 3250 NA 3450 3650 3625 4675 ## Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## 3475 4250 3300 3700 3200 3800 4400 3700 ## Torgersen Torgersen Torgersen Torgersen Biscoe Biscoe Biscoe Biscoe ## 3450 4500 3325 4200 3400 3600 3800 3950 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Dream Dream ## 3800 3800 3550 3200 3150 3950 3250 3900 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3300 3900 3325 4150 3950 3550 3300 4650 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3150 3900 3100 4400 3000 4600 3425 2975 ## Dream Dream Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 3450 4150 3500 4300 3450 4050 2900 3700 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 3550 3800 2850 3750 3150 4400 3600 4050 ## Biscoe Biscoe Biscoe Biscoe Torgersen Torgersen Torgersen Torgersen ## 2850 3950 3350 4100 3050 4450 3600 3900 ## Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## 3550 4150 3700 4250 3700 3900 3550 4000 ## Torgersen Torgersen Torgersen Torgersen Dream Dream Dream Dream ## 3200 4700 3800 4200 3350 3550 3800 3500 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3950 3600 3550 4300 3400 4450 3300 4300 ## Dream Dream Dream Dream Biscoe Biscoe Biscoe Biscoe ## 3700 4350 2900 4100 3725 4725 3075 4250 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 2925 3550 3750 3900 3175 4775 3825 4600 ## Biscoe Biscoe Biscoe Biscoe Torgersen Torgersen Torgersen Torgersen ## 3200 4275 3900 4075 2900 3775 3350 3325 ## Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen Torgersen ## 3150 3500 3450 3875 3050 4000 3275 4300 ## Torgersen Torgersen Torgersen Torgersen Dream Dream Dream Dream ## 3050 4000 3325 3500 3500 4475 3425 3900 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3175 3975 3400 4250 3400 3475 3050 3725 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3000 3650 4250 3475 3450 3750 3700 4000 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4500 5700 4450 5700 5400 4550 4800 5200 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4400 5150 4650 5550 4650 5850 4200 5850 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4150 6300 4800 5350 5700 5000 4400 5050 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 5000 5100 4100 5650 4600 5550 5250 4700 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 5050 6050 5150 5400 4950 5250 4350 5350 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 3950 5700 4300 4750 5550 4900 4200 5400 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 5100 5300 4850 5300 4400 5000 4900 5050 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4300 5000 4450 5550 4200 5300 4400 5650 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4700 5700 4650 5800 4700 5550 4750 5000 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 5100 5200 4700 5800 4600 6000 4750 5950 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4625 5450 4725 5350 4750 5600 4600 5300 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4875 5550 4950 5400 4750 5650 4850 5200 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4925 4875 4625 5250 4850 5600 4975 5500 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4725 5500 4700 5500 4575 5500 5000 5950 ## Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe Biscoe ## 4650 5500 4375 5850 4875 6000 4925 NA ## Biscoe Biscoe Biscoe Biscoe Dream Dream Dream Dream ## 4850 5750 5200 5400 3500 3900 3650 3525 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3725 3950 3250 3750 4150 3700 3800 3775 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3700 4050 3575 4050 3300 3700 3450 4400 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3600 3400 2900 3800 3300 4150 3400 3800 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3700 4550 3200 4300 3350 4100 3600 3900 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3850 4800 2700 4500 3950 3650 3550 3500 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3675 4450 3400 4300 3250 3675 3325 3950 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3600 4050 3350 3450 3250 4050 3800 3525 ## Dream Dream Dream Dream Dream Dream Dream Dream ## 3950 3650 3650 4000 3400 3775 4100 3775 # it has to be in the order of numeric, character and then prints matched observations Is pull() helpful? Is this useful for work or is it irrelevant?\nPros:\ndplyr::pull() can be worked with or without quotes, however with other similar functions like purrr:pluck(), you need to use quotes around the variables you’re calling.\nEasy to read and understand for non-coders or beginners.\nSeeing pull(data, var) is nicer on the eyes than other variations like data$var and any other type of variation that uses different types of characters within the code.\nCons:\nFrom digging around on the internet a bit, through forums and articles, it seems like pull() overall isn’t really that functional for more complex wrangling.\nCannot use as many types of “verbs” as select() does.\nSelect() offers “starts_with()”, “ends_with()”, “contains()”, and “everything()” which can be easier to create tibbles with columns that all contain similar values.\nExample in penguins data:\ncan utilize “ends_with()” to pull columns with the same measurements\nbill_length_mm, bill_depth_mm, flipper_length_mm\nComparing to select(), pull() creates a vector, while select() creates a tibble.\npenguins %\u0026gt;% pull(species) ## [1] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [8] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [15] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [22] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [29] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [36] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [43] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [50] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [57] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [64] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [71] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [78] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [85] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [92] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [99] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [106] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [113] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [120] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [127] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [134] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [141] Adelie Adelie Adelie Adelie Adelie Adelie Adelie ## [148] Adelie Adelie Adelie Adelie Adelie Gentoo Gentoo ## [155] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [162] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [169] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [176] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [183] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [190] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [197] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [204] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [211] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [218] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [225] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [232] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [239] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [246] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [253] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [260] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [267] Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo Gentoo ## [274] Gentoo Gentoo Gentoo Chinstrap Chinstrap Chinstrap Chinstrap ## [281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap ## [344] Chinstrap ## Levels: Adelie Chinstrap Gentoo penguins %\u0026gt;% select(species) ## # A tibble: 344 x 1 ## species ## \u0026lt;fct\u0026gt; ## 1 Adelie ## 2 Adelie ## 3 Adelie ## 4 Adelie ## 5 Adelie ## 6 Adelie ## 7 Adelie ## 8 Adelie ## 9 Adelie ## 10 Adelie ## # ... with 334 more rows Select() appears to be easier to manipulate and sort through, as well as the verbs that it offers.\nPull() doesn’t offer much but can be a simple way to skim over values or observations from specific columns.\nConclusion Pull() is good for beginners, it’s simple, it’s readable, it’s a good way to dip your toes into data wrangling but there’s not much you can do with it.\nIt is often overlooked for being so bland;\nThis site states;\n“Main data manipulation functions”\nThere are 8 fundamental data verbs/functions which are;\nfilter(): Pick rows (observations/samples) based on their values\ndistinct(): Remove duplicate rows\narrange(): Reorder the rows\nselect(): Select columns (variables) by their names\nrename(): Rename columns\nmutate() and transmutate(): Add/create new variables\nsummarise(): Compute statistical summaries (e.g., computing the mean or the sum) Pull is not included probably because the results are too uneventful and bland.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"094e6f8acfb51f2c1a144ced9c4a45bf","permalink":"https://sph-r-programming-2023.netlify.app/functions/dplyr_pull/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/dplyr_pull/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: dplyr::pull() Function of the Week: dplyr::pull() Saffron Evergreen 2022-03-02 Function of the Week Submit both the .Rmd and the .html files. Function: Pull() In this document, I will introduce the pull() function, which is within the tidyverse package. I will show what it’s for, what it does and doesn’t do. library(tidyverse) library(palmerpenguins) data(penguins) print(head(penguins)) ## # A tibble: 6 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_~ body_mass_g sex ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; ## 1 Adelie Torge~ 39.","tags":null,"title":"dplyr::pull()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: slice_min() \u0026amp; slice_max() Function of the Week: slice_min() \u0026amp; slice_max() Isabel English 2022-03-16 slice_min() \u0026amp; slice_max() In this document, I will introduce the slice_min() \u0026amp; slice_max() functions and show what they’re used for.\nLoading my data I always enjoy looking at the datasets FiveThirtyEight uses, because they display data so nicely. For this presentation, I chose to look at Club Soccer Predictions–specifically, the English (Barclay’s) Premier League. To simplify this example, I grabbed a subset of data that included only the Premier League teams and their current ranking data.\nspi_global_rankings \u0026lt;- read_excel(\u0026quot;20220316_FiveThirtyEight_soccer-spi_data/spi_global_rankings.xlsx\u0026quot;, sheet = 1, skip = 0, na = \u0026quot;NA\u0026quot;) barclays_premier \u0026lt;- subset(spi_global_rankings, league == \u0026quot;Barclays Premier League\u0026quot;) print(barclays_premier) ## # A tibble: 20 × 7 ## rank prev_rank name league off def spi ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 Manchester City Barclays Premier … 2.9 0.2 93.7 ## 2 3 3 Liverpool Barclays Premier … 2.95 0.29 92.8 ## 3 4 4 Chelsea Barclays Premier … 2.4 0.26 89.3 ## 4 11 12 Arsenal Barclays Premier … 2.22 0.52 82.2 ## 5 14 15 Tottenham Hotspur Barclays Premier … 2.34 0.67 80.3 ## 6 17 17 Manchester United Barclays Premier … 2.19 0.67 78.3 ## 7 22 28 Aston Villa Barclays Premier … 2.03 0.64 76.7 ## 8 30 29 West Ham United Barclays Premier … 2.01 0.73 74.3 ## 9 32 27 Brighton and Hove Albion Barclays Premier … 1.85 0.62 74.2 ## 10 34 45 Wolverhampton Barclays Premier … 1.72 0.55 73.8 ## 11 38 41 Crystal Palace Barclays Premier … 1.89 0.69 73.1 ## 12 50 47 Leicester City Barclays Premier … 2.07 0.96 69.8 ## 13 55 48 Southampton Barclays Premier … 1.94 0.89 69.2 ## 14 61 66 Brentford Barclays Premier … 1.78 0.85 67.1 ## 15 65 68 Newcastle Barclays Premier … 1.76 0.85 66.7 ## 16 74 70 Burnley Barclays Premier … 1.62 0.83 64.4 ## 17 78 74 Everton Barclays Premier … 1.73 0.95 63.8 ## 18 91 78 Leeds United Barclays Premier … 1.85 1.14 61.6 ## 19 103 100 Watford Barclays Premier … 1.65 1.08 59 ## 20 151 146 Norwich City Barclays Premier … 1.51 1.19 53.0 The rankings appear to be missing spots, but we have to remember that this was pulling a subset of the greater dataset which was ranking all International Club Teams (of which there are 640).\nWhat is it for? The data is still in rank order by Soccer Power Ranking (SPI), so if I just pull the top 5 teams, I’ll know who the top teams to watch in the Premier League are. I can do this using slice_min() for best (lowest #) ranking:\nslice_min(barclays_premier, order_by = rank, n = 5, with_ties = TRUE) ## # A tibble: 5 × 7 ## rank prev_rank name league off def spi ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 Manchester City Barclays Premier League 2.9 0.2 93.7 ## 2 3 3 Liverpool Barclays Premier League 2.95 0.29 92.8 ## 3 4 4 Chelsea Barclays Premier League 2.4 0.26 89.3 ## 4 11 12 Arsenal Barclays Premier League 2.22 0.52 82.2 ## 5 14 15 Tottenham Hotspur Barclays Premier League 2.34 0.67 80.3 I can also do this by using slice_max() for highest SPI:\nslice_max(barclays_premier, order_by = spi, n = 5, with_ties = TRUE) ## # A tibble: 5 × 7 ## rank prev_rank name league off def spi ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 Manchester City Barclays Premier League 2.9 0.2 93.7 ## 2 3 3 Liverpool Barclays Premier League 2.95 0.29 92.8 ## 3 4 4 Chelsea Barclays Premier League 2.4 0.26 89.3 ## 4 11 12 Arsenal Barclays Premier League 2.22 0.52 82.2 ## 5 14 15 Tottenham Hotspur Barclays Premier League 2.34 0.67 80.3 Is it helpful? These functions are helpful when you want to quickly visualize the top or bottom of a list, maybe to have a quick understanding of your data and/or how it is being organized while you’re working, but I imagine that combining them with some more filtering would give them even more power. For example, highlighting these top 5 Premier League teams, but from the original data of 640 teams. Or perhaps the top students from each of 6 classes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"855e27a96cba3ea62a78cc49bab654c3","permalink":"https://sph-r-programming-2023.netlify.app/functions/dplyr_slice_min_slice_max/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/dplyr_slice_min_slice_max/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: slice_min() \u0026amp; slice_max() Function of the Week: slice_min() \u0026amp; slice_max() Isabel English 2022-03-16 slice_min() \u0026amp; slice_max() In this document, I will introduce the slice_min() \u0026amp; slice_max() functions and show what they’re used for. Loading my data I always enjoy looking at the datasets FiveThirtyEight uses, because they display data so nicely. For this presentation, I chose to look at Club Soccer Predictions–specifically, the English (Barclay’s) Premier League.","tags":null,"title":"dplyr::slice_min/max()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: You 2022-03-09 Function Name In this document, I will introduce the fct_infreq() function and show what it’s for.\n#load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(forcats) #example dataset library(palmerpenguins) data(penguins) What is it for? This function changes the order of the levels by number of observations within each level, starting with the largest number of observations.\nArguments * f * A factor\nordered A logical which determines the “ordered” status of the output factor. NA preserves the existing status of the factor. f \u0026lt;- (c(\"red\", \"yellow\", \"yellow\", \"blue\", \"blue\", \"yellow\", \"red\", \"yellow\", \"blue\", \"red\", \"yellow\", \"rainbow\", \"yellow\", \"blue\")) f\u0026lt;-factor(f) summary(f) #According to this, we should see yellow in our data set first, then blue, then red, then rainbow ## blue rainbow red yellow ## 4 1 3 6 change_f \u0026lt;- fct_infreq(f) summary(change_f) ## yellow blue red rainbow ## 6 4 3 1 Is it helpful? I don’t think this is super relevant because if you were to need to automatically set the order of a factor this way from a large data set, R actually automatically does this. So this is really only helpful when we create our own vectors or datasets which I rarely have done.\nExample:\nsummary(penguins$island) ## Biscoe Dream Torgersen ## 168 124 52 Maybe it can be helpful if you purposefully re-level your vector, but then want it back to be ordered by frequency again (R starts with largest frequency).\nlibrary(janitor) ## ## Attaching package: 'janitor' ## The following objects are masked from 'package:stats': ## ## chisq.test, fisher.test penguins$island_relevel \u0026lt;- relevel(penguins$island, \"Torgersen\") penguins %\u0026gt;% tabyl(island_relevel) ## island_relevel n percent ## Torgersen 52 0.1511628 ## Biscoe 168 0.4883721 ## Dream 124 0.3604651 Now back to original with function.\npenguins$change_f \u0026lt;- fct_infreq(penguins$island_relevel) penguins %\u0026gt;% tabyl(change_f) ## change_f n percent ## Biscoe 168 0.4883721 ## Dream 124 0.3604651 ## Torgersen 52 0.1511628 Resources https://forcats.tidyverse.org/reference/fct_inorder.html\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"bc78479f905f99cb58f1588c12312983","permalink":"https://sph-r-programming-2023.netlify.app/functions/forcats_fct_infreq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/forcats_fct_infreq/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: You 2022-03-09 Function Name In this document, I will introduce the fct_infreq() function and show what it’s for. #load tidyverse up library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.4 ✓ stringr 1.4.0 ## ✓ readr 2.1.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(forcats) #example dataset library(palmerpenguins) data(penguins) What is it for?","tags":null,"title":"forcats::fct_infreq()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Kathryn Liu 2022-02-02 fct_lump() In this document, I will introduce the fct_lump() function and show what it’s for.\n#load packages pacman::p_load( tidyverse, readxl, here, janitor, dplyr ) #load data for examples smoke_complete \u0026lt;- read_excel(\u0026quot;data/smoke_complete.xlsx\u0026quot;, sheet =1, na= \u0026quot;NA\u0026quot;) #prepare data for analysis smoke_sample \u0026lt;- smoke_complete %\u0026gt;% #create small sample sample_n(., 10) %\u0026gt;% #keep only relevant fields select(primary_diagnosis, tumor_stage, disease) #output example data set for reference (smoke_sample) ## # A tibble: 10 x 3 ## primary_diagnosis tumor_stage disease ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 C34.1 stage ib LUSC ## 2 C53.9 not reported CESC ## 3 C34.1 stage ib LUSC ## 4 C34.1 stage ia LUSC ## 5 C67.1 stage ii BLCA ## 6 C34.1 stage ia LUSC ## 7 C34.9 stage iiib LUSC ## 8 C67.9 stage iii BLCA ## 9 C34.1 stage iib LUSC ## 10 C34.9 stage ib LUSC What is it for? fct_lump() is a family of functions used for bucketing levels into a category called “other” based on their frequencies. There are four functions within the fct_lump() family.\nfct_lump_min()\nfct_lump_prop()\nfct_lump_n()\nfct_lump_lowfreq()\n1. fct_lump_min() This function buckets levels which appear fewer than n times.\nExample #create frequency table of primary_diagnosis for reference freq_primary_diagnosis \u0026lt;- smoke_sample %\u0026gt;% tabyl(primary_diagnosis) #sort descending freq_primary_diagnosis %\u0026gt;% arrange(desc(percent)) ## primary_diagnosis n percent ## C34.1 5 0.5 ## C34.9 2 0.2 ## C53.9 1 0.1 ## C67.1 1 0.1 ## C67.9 1 0.1 #Set any levels which occur fewer than 2 times to \u0026quot;Suppressed\u0026quot;. Keep all other entries as-is. (fct_lump_min(smoke_sample$primary_diagnosis, 2, other_level = \u0026quot;Suppressed\u0026quot;)) ## [1] C34.1 Suppressed C34.1 C34.1 Suppressed C34.1 ## [7] C34.9 Suppressed C34.1 C34.9 ## Levels: C34.1 C34.9 Suppressed #Note that the other_level = \u0026quot;name\u0026quot; argument can be used to specify a bucket name aside from the default \u0026quot;other\u0026quot;. Is it helpful? I would use this function if I had concerns about HIPPA compliance and wanted to suppress information relating to rare traits, diseases, or procedures that might identify a patient.\n2. fct_lump_prop() This function buckets levels which make up less than p, a specified proportion, of the data.\nExample #create frequency table of tumor_stage for reference freq_tumor_stage \u0026lt;- smoke_sample %\u0026gt;% tabyl(tumor_stage) #sort descending freq_tumor_stage %\u0026gt;% arrange(desc(percent)) ## tumor_stage n percent ## stage ib 3 0.3 ## stage ia 2 0.2 ## not reported 1 0.1 ## stage ii 1 0.1 ## stage iib 1 0.1 ## stage iii 1 0.1 ## stage iiib 1 0.1 #Set any levels which make up 10% or less of the data to \u0026quot;Rare\u0026quot;, and keep all other levels as-is. (fct_lump_prop(smoke_sample$tumor_stage, 0.10, other_level = \u0026quot;Rare\u0026quot;)) ## [1] stage ib Rare stage ib stage ia Rare stage ia Rare Rare ## [9] Rare stage ib ## Levels: stage ia stage ib Rare #Set any levels which make up more than 10% of the data to \u0026quot;Common\u0026quot;, and keep all other levels as-is. (fct_lump_prop(smoke_sample$tumor_stage, -0.10, other_level = \u0026quot;Common\u0026quot;)) ## [1] Common not reported Common Common stage ii ## [6] Common stage iiib stage iii stage iib Common ## Levels: not reported stage ii stage iib stage iii stage iiib Common Is it helpful? This function could potentially be useful, if you wanted to bucket and blind only extreme results. However, it would not be helpful if you wanted to bucket all entries of a particular field.\n3. fct_lump_n(): This function buckets levels which appear fewer than the most common n levels.\nExample #create frequency table of tumor_stage for reference freq_tumor_stage \u0026lt;- smoke_sample %\u0026gt;% tabyl(tumor_stage) #sort descending freq_tumor_stage %\u0026gt;% arrange(desc(percent)) ## tumor_stage n percent ## stage ib 3 0.3 ## stage ia 2 0.2 ## not reported 1 0.1 ## stage ii 1 0.1 ## stage iib 1 0.1 ## stage iii 1 0.1 ## stage iiib 1 0.1 #Keep the the most common level of primary_diagnosis, and set any remaining levels to \u0026quot;other\u0026quot;. fct_lump_n(smoke_sample$tumor_stage, 1) ## [1] stage ib Other stage ib Other Other Other Other Other ## [9] Other stage ib ## Levels: stage ib Other Is it helpful? I cannot think of a situation in my work where this function would be useful. I would prefer to use a combination of the tabyl() and arrange() functions (as seen at the top of the code for this example) to determine the most common level(s) and make bucketing determinations after manual review, as frequencies may change with refreshed data sets.\n4. fct_lump_lowfreq() This function buckets the least frequent levels to “other”, while still keeping the “other” bucket as the smallest level.\nExample #example where fails #create frequency table of primary_diagnosis for reference freq_primary_diagnosis \u0026lt;- smoke_sample %\u0026gt;% tabyl(primary_diagnosis) #sort descending freq_primary_diagnosis %\u0026gt;% arrange(desc(percent)) ## primary_diagnosis n percent ## C34.1 5 0.5 ## C34.9 2 0.2 ## C53.9 1 0.1 ## C67.1 1 0.1 ## C67.9 1 0.1 #Bucket levels which make up the lowest frequency fct_lump_lowfreq(smoke_sample$primary_diagnosis) ## [1] C34.1 C53.9 C34.1 C34.1 C67.1 C34.1 C34.9 C67.9 C34.1 C34.9 ## Levels: C34.1 C34.9 C53.9 C67.1 C67.9 #example where works #create frequency table of disease for reference freq_disease \u0026lt;- smoke_sample %\u0026gt;% tabyl(disease) #sort descending freq_disease %\u0026gt;% arrange(desc(disease)) ## disease n percent ## LUSC 7 0.7 ## CESC 1 0.1 ## BLCA 2 0.2 #Bucket levels which make up the lowest frequency fct_lump_lowfreq(smoke_sample$disease) ## [1] LUSC Other LUSC LUSC Other LUSC LUSC Other LUSC LUSC ## Levels: LUSC Other Is it helpful? I cannot think of a scenario in my work where I would find this helpful.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"18682021c9787d0f8871b8e0aaa0c4e9","permalink":"https://sph-r-programming-2023.netlify.app/functions/forcats_fct_lump/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/forcats_fct_lump/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Kathryn Liu 2022-02-02 fct_lump() In this document, I will introduce the fct_lump() function and show what it’s for. #load packages pacman::p_load( tidyverse, readxl, here, janitor, dplyr ) #load data for examples smoke_complete \u0026lt;- read_excel(\u0026quot;data/smoke_complete.xlsx\u0026quot;, sheet =1, na= \u0026quot;NA\u0026quot;) #prepare data for analysis smoke_sample \u0026lt;- smoke_complete %\u0026gt;% #create small sample sample_n(., 10) %\u0026gt;% #keep only relevant fields select(primary_diagnosis, tumor_stage, disease) #output example data set for reference (smoke_sample) ## # A tibble: 10 x 3 ## primary_diagnosis tumor_stage disease ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 C34.","tags":null,"title":"forcats::fct_lump()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Ashley Blair 02/03/2022 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing\nFor this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.\nBreaks_Pretty In this document, I will introduce the Breaks_Pretty function and show what it’s for.\n#load tidyverse up library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.1.4 v stringr 1.4.0 ## v readr 2.1.1 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() #example dataset library(palmerpenguins) #breaks pretty is in \u0026quot;scales\u0026quot; package library(scales) ## ## Attaching package: \u0026#39;scales\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## discard ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## col_factor What is it for? The breaks_pretty function is used to create easy, incremental break formatting - n= will specify the amount of breaks. This function is used more commonly for dates/times. Extended_breaks() is more commonly used for numeric scales. In the example below, I used numeric variables anyway.\n#create plot \u0026amp; designate how many \u0026quot;breaks\u0026quot; ggplot(penguins, aes(x=bill_length_mm, y=flipper_length_mm))+ geom_point() + scale_x_continuous(name= \u0026quot;Bill Length in mm\u0026quot;, breaks = breaks_pretty(4)) ## Warning: Removed 2 rows containing missing values (geom_point). scale_y_continuous(name= \u0026quot;Flipper Length in mm\u0026quot;, breaks = breaks_pretty(8)) ## \u0026lt;ScaleContinuousPosition\u0026gt; ## Range: ## Limits: 0 -- 1 #R doesn\u0026#39;t always use the amount of \u0026quot;breaks\u0026quot; that you assign - apparently because it wants to best fit the data. For example - it won\u0026#39;t allow for n=50 for y-axis. ggplot(penguins, aes(x=bill_length_mm, y=flipper_length_mm))+ geom_point() + scale_x_continuous(name= \u0026quot;Bill Length in mm\u0026quot;, breaks = breaks_pretty(2)) ## Warning: Removed 2 rows containing missing values (geom_point). scale_y_continuous(name= \u0026quot;Flipper Length in mm\u0026quot;, breaks = breaks_pretty(50)) ## \u0026lt;ScaleContinuousPosition\u0026gt; ## Range: ## Limits: 0 -- 1 Here is an example using dates!\none_year \u0026lt;- as.POSIXct(c(\u0026quot;2022-01-01\u0026quot;, \u0026quot;2023-01-01\u0026quot;)) demo_datetime(one_year) ## scale_x_datetime() demo_datetime(one_year, breaks = breaks_pretty(12)) ## scale_x_datetime(breaks = breaks_pretty(12)) demo_datetime(one_year, breaks = breaks_pretty(6)) ## scale_x_datetime(breaks = breaks_pretty(6)) demo_datetime(one_year, breaks = breaks_pretty(100)) ## scale_x_datetime(breaks = breaks_pretty(100)) Is it helpful? Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\nI find breaks_pretty much more useful in the dates example! Which makes sense considering it’s not generally used for numerical variables (penguin example).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"7def90a3f8c82d89506205b2badb014b","permalink":"https://sph-r-programming-2023.netlify.app/functions/scales_breaks_pretty/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/scales_breaks_pretty/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Ashley Blair 02/03/2022 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing For this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.","tags":null,"title":"scales::breaks_pretty()","type":"docs"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week⚖️:percent Function of the Week⚖️:percent Barbara Cassese 3/08/2022 scales::label_percent()and scales::percent_format(scale = 1)’ In this document, I will introduce the `scales::label_percent() and The percent() function .\nlibrary(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.1.4 v stringr 1.4.0 ## v readr 2.1.1 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(scales) ## ## Attaching package: \u0026#39;scales\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## discard ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## col_factor library(dplyr) library(ggplot2) library(palmerpenguins) data(\u0026quot;penguins\u0026quot;) What is it for? percent () is a function from an old interface. The percent() function formats numbers as percentages and can allow for accurate decimal places.Percent_format is a generalized version of percent(). Label_percent is used to create percentage_format labels on ggplots.\nsex1\u0026lt;-penguins %\u0026gt;% count(sex) %\u0026gt;% mutate(pct= n/sum(n))%\u0026gt;% print() ## # A tibble: 3 x 3 ## sex n pct ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 female 165 0.480 ## 2 male 168 0.488 ## 3 \u0026lt;NA\u0026gt; 11 0.0320 sex1 %\u0026gt;% ggplot(aes(sex, pct)) + geom_col()+ scale_y_continuous(labels=scales::label_percent()) `scales::label_percent()’is useful , especially if you have not created the percentage (multiplied by 100 ) in the mutate function. I do not think there is any other way to create the labels as a percentage unless you change the axis titles using labs(), but that would only change the title of the axis not the values to a percentage. Percent_format is useful as well, you could create percentages by mutating and creating a new function and variable, but that has more coding steps and unnecessary.I think defining the accuracy and significant figures is helpful as well.\npct1 \u0026lt;- scales::percent_format(scale = 1) pct1(100) ## [1] \u0026quot;100%\u0026quot; data \u0026lt;- c(.3, .7, .14, .18, .22, .78) percent(data, accuracy = 1) ## [1] \u0026quot;30%\u0026quot; \u0026quot;70%\u0026quot; \u0026quot;14%\u0026quot; \u0026quot;18%\u0026quot; \u0026quot;22%\u0026quot; \u0026quot;78%\u0026quot; percent(data, accuracy = 0.1) ## [1] \u0026quot;30.0%\u0026quot; \u0026quot;70.0%\u0026quot; \u0026quot;14.0%\u0026quot; \u0026quot;18.0%\u0026quot; \u0026quot;22.0%\u0026quot; \u0026quot;78.0%\u0026quot; Is it helpful? Yes, I think label_percent is useful when creating a ggplot.Percent and percent format are also useful, it is more efficient than creating a mutate function.The percent_format() and Percent()can provide an accurate number which is useful.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"bb723f6d4b90408888335c9dbff9f923","permalink":"https://sph-r-programming-2023.netlify.app/functions/scales_percent/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/scales_percent/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week⚖️:percent Function of the Week⚖️:percent Barbara Cassese 3/08/2022 scales::label_percent()and scales::percent_format(scale = 1)’ In this document, I will introduce the `scales::label_percent() and The percent() function . library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.1.4 v stringr 1.4.0 ## v readr 2.1.1 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(scales) ## ## Attaching package: \u0026#39;scales\u0026#39; ## The following object is masked from \u0026#39;package:purrr\u0026#39;: ## ## discard ## The following object is masked from \u0026#39;package:readr\u0026#39;: ## ## col_factor library(dplyr) library(ggplot2) library(palmerpenguins) data(\u0026quot;penguins\u0026quot;) What is it for?","tags":null,"title":"scales::percent_format()","type":"docs"},{"authors":null,"categories":null,"content":" Here’s your roadmap for the quarter!\nReadings are supplemental to each lecture session Assignments are due by 11:59 PM on the day they are due Class materials (slides, in-class activities, etc.) will be added on the day of class Please note that this schedule is tentative. I want us to learn concepts, rather than have a lot of material.\nPart 1: tidyverse Basics Reading Assignment Class January 11 Part 1: Introduction to course/expectations, Intro to R/RStudio, Functions, Vectors, Data Types January 18 Part 2: Loading Data, data.frames, and ggplot2 January 25 [NO CLASS, ASYNCHRONOUS VIDEOS] Part 3: dplyr: subsetting using filter()/select() February 1 Part 4. dplyr: mutate(),across(), case_when(), factors, ggplot2 boxplots, facets, scales February 8 Part 5. summarize() and group_by(), doing things with multiple tables (left_join() etc), reshaping data (i.e. pivot_longer()) TBD Take Home Midterm Assigned Part 2: Intermediate Topics Reading Assignment Class February 12 Part 6. Intro to functions, working with lists February 15 Take home midterm due February 22 Part 7: Functions/batch processing/purrr March 1 Part 8. More with factors, dates, strings. March 8 Part 9. Intro to stats/formulas/broom/More Purrr TBD Final Project Assigned March 15 Part 10. More Stats Stuff/Summary Tables March 22 Part 11. Advanced Functions and Loose Ends TBD Final Project Due ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"https://sph-r-programming-2023.netlify.app/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Here’s your roadmap for the quarter!\nReadings are supplemental to each lecture session Assignments are due by 11:59 PM on the day they are due Class materials (slides, in-class activities, etc.) will be added on the day of class Please note that this schedule is tentative. I want us to learn concepts, rather than have a lot of material.\nPart 1: tidyverse Basics Reading Assignment Class January 11 Part 1: Introduction to course/expectations, Intro to R/RStudio, Functions, Vectors, Data Types January 18 Part 2: Loading Data, data.","tags":null,"title":"Schedule","type":"page"},{"authors":null,"categories":null,"content":" \u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Ngoc Le 2022-03-02 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing\nFor this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.\nstringr::str_detect() In this document, I will introduce the str_detect() function and show what it’s for.\n#load tidyverse up library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.7 ## v tidyr 1.1.4 v stringr 1.4.0 ## v readr 2.1.1 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() What is it for? Given a vector, str_detect() looks for and returns whether there is a presence or absence of a pattern in thact vector. The str_detect() function takes two arguments. The first is a vector, and the second is the pattern you are looking for.\nflowers \u0026lt;- c(\u0026quot;tulip\u0026quot;, \u0026quot;iris\u0026quot;, \u0026quot;hibicus\u0026quot;, \u0026quot;poppy\u0026quot;, \u0026quot;daisy\u0026quot;) str_detect(flowers, \u0026quot;i\u0026quot;) ## [1] TRUE TRUE TRUE FALSE TRUE str_detect(flowers, \u0026quot;^i\u0026quot;) ## [1] FALSE TRUE FALSE FALSE FALSE str_detect(flowers, \u0026quot;y$\u0026quot;) ## [1] FALSE FALSE FALSE TRUE TRUE str_detect(flowers, \u0026quot;[aeiou]\u0026quot;) ## [1] TRUE TRUE TRUE TRUE TRUE str_detect() can also be used in combination with filter() to subset a data set.\ndf \u0026lt;- data.frame(Country = c(\u0026quot;Australia\u0026quot;, \u0026quot;Canada\u0026quot;, \u0026quot;Japan\u0026quot;, \u0026quot;India\u0026quot;, \u0026quot;Spain\u0026quot;)) df ## Country ## 1 Australia ## 2 Canada ## 3 Japan ## 4 India ## 5 Spain df %\u0026gt;% filter(str_detect(Country, \u0026quot;Australia|Canada\u0026quot;)) ## Country ## 1 Australia ## 2 Canada df %\u0026gt;% filter(str_detect(Country, \u0026quot;Australia|Canada\u0026quot;, negate = TRUE)) ## Country ## 1 Japan ## 2 India ## 3 Spain Is it helpful? It is really helpful to look for patterns in a large dataset. However, it is equivalent togrepl(). It can also be repalced by other functions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"b5dd344143792cf65998628ac3299b94","permalink":"https://sph-r-programming-2023.netlify.app/functions/stringr_str_detect/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/functions/stringr_str_detect/","section":"functions","summary":"\u003c!DOCTYPE html\u003e Function of the Week: Function of the Week: Ngoc Le 2022-03-02 Submission Instructions Please sign up for a function here: https://docs.google.com/spreadsheets/d/1-RWAQTlLwttjFuZVAtSs8OiHIwu6AZLUdWugIHHTWVo/edit?usp=sharing For this assignment, please submit both the .Rmd and the .html files. I will add it to the website. Remove your name from the Rmd if you do not wish it shared. If you select a function which was presented last year, please develop your own examples and content.","tags":null,"title":"stringr::str_detect()","type":"docs"},{"authors":null,"categories":null,"content":" Course Description Credit Hours Learning Objectives Course Website Office Hours Prerequisites or Concurrent Enrollment Requirements Faculty Information Instructor Teaching Assistant Attendance Requirements Homework Function of the week Midterm and Final Grading Policy Late Policy Code of Conduct Required Texts or Readings Words of Encouragement LeaRning is Social Copyright Information School of Public Health Handbook Syllabus Changes and Retention Syllabus Statement Regarding Disability Services Commitment of Equity and Inclusion Academic Honesty Use of Sakai Instructor Dr. Jessica Minnier S Waterfront minnier@ohsu.edu @datapointier Course details Wednesdays Jan 11 – March 22, 2023 3:15–6:05 PM See Sakai Contacting me E-mail or Slack is the best way to get in contact with me. I will try to respond to all course-related e-mails within 1 business day.\nCourse Description This course is meant to be a gentle introduction to data wrangling and visualization using the tidyverse in R. This course focuses on practical data science skills in R (loading data, data wrangling, visualization, automation, machine learning, and running statistical models) that you’ll use almost everyday in your work. It is meant for both beginners and students wanting to brush up on their R skills.\nCredit Hours 3 credit hours.\nLearning Objectives Understand and utilize R/RStudio. Understand basic data types and data structures in R. Familiarize and load data files (Excel, Comma Separated Value files) into R/Rstudio, with tips on formatting. Visualize datasets using ggplot2 and understand how to build basic plots using ggplot2 syntax. Filter and format data in R for use with various routines. Execute and Interpret some basic statistics in R. Automate repetitive tasks in R, such as loading a folder of files. If time allows:\nCreate nice tables in our R markdown reports with gt and/or kableExtra. Build basic interactive applications with shiny. Course Website All course information will be available here:\nhttps://sph-r-programming-2023.netlify.com/\nInformation will also be available on the Sakai website.\nCourse discussions will be done in the class Slack channel. Invites will be sent before class.\nOffice Hours Office Hours will be held by request via Zoom using the class zoom link (see Sakai, or, outlook invite). Use the office hours request form (see Sakai for link) to request a 30 minute individual or small group meeting with me.\nPrerequisites or Concurrent Enrollment Requirements One course in statistics.\nFaculty Information Instructor Jessica Minnier, PhD\nPreferred Method of Contact: Email/Slack\nExpected Response Time: 1 business day\nTeaching Assistant Brad H.\nAttendance Requirements Please try to attend class, but I understand that sometimes it’s easier or necessary to log in virtually or watch a recording. Attendance is part of the grade but I only require that you fill out 5 post-class surveys (out of 11) as a way of telling me that you watched the recordings or came to class and learned the available material for that week. However, if you fill out all 11 surveys, your attendance score will be 11/5 so you have some easy extra credit available there as well.\nClasses will be recorded, but I cannot guarantee the in person format will lend itself to effective recordings. Again, those who are curious and ask questions will learn quite a bit. You can go through all of last year’s materials on your own, but you signed up for a live in person course so definitely make the most of having people around to answer your questions!\nHomework There will be homework assigned weekly using R markdown. It will be due via Sakai upload at 11:55pm the night of the following week’s class (unless otherwise noted). Please turn in both your .Rmd and knitted .html file.\nThe homework with the lowest score will be dropped from the calculation. Some homeworks may have extra credit, so it’s possible to obtain \u0026gt; 100% on the homework portion.\nFunction of the week Please choose a function from the function of the week sign up sheet (see Sakai homepage for link). In the dropbox folder there is a template for format of the week R markdown and presentation. You may choose a week to present your function to the class. The presentation should be short, around 5 minutes. If presenting to the class feels prohibitive, you may submit a 5-10 minute screen recording with your voice narrating the presentation, and this will be distributed to the class. Function of the week presentations will start in week 4.\nMidterm and Final Midterm and final projects/tests will be take home. The midterm will be a project based on a data set. The final will likely be based on a data set that I assign. Previous years’ midterms can be found on the class websites:\nhttps://sph-r-programming-2022-midterms.netlify.app/ https://sph-midterm-projects.netlify.app/ (2021) I will create a similar website for this year’s midterm projects. If you do not wish your project to be on the public facing website, just let me know. Or, it can be posted anonymously.\nGrading Policy Attendance 5% Midterm Project 20% Function of the Week 10% Homework Assignments 45% Final Project 20% Late Policy Students get 1 free assignment to submit late without penalties. Please email the instructor and the TA through Sakai that you need more time. If you need accommodation, please email us so we can figure out a way to help you.\nCode of Conduct This class is governed by the BioData Club Code of Conduct: https://biodata-club.github.io/code_of_conduct/\nAnd as students of an OHSU course, we must abide by the OHSU Code of Conduct: https://www.ohsu.edu/integrity-department/code-conduct\nThis class is meant to be a psychologically safe space where it’s ok to ask questions. We want to normalize your own curiosity and fuel your desire to learn more.\nIf you are disruptive to class learning or disparaging to other students, I may mute you for the day. I am very serious about this.\nRequired Texts or Readings We will be drawing on the following online textbooks during class and labs. These books are online and free, though you can order them as textbooks if you prefer that format.\nR for Data Science. Garret Grolemund and Hadley Wickham. https://r4ds.had.co.nz/\nGetting Used to R, RStudio, and RMarkdown. Chester Ismay. https://ismayc.github.io/rbasics-book/\nData Science: A First Introduction. Tiffany Timbers, Trevor Campbell, Melissa Lee. https://datasciencebook.ca/\nRMarkdown for Scientists. Nick Tierney. https://rmd4sci.njtierney.com/\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse. Chester Ismay and Albert Y. Kim. https://moderndive.com/\nAdvanced R. Hadley Wickham. https://adv-r.hadley.nz/\nWords of Encouragement This was adopted from Andrew Heiss. Thanks!\nI promise you can succeed in this class.\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2—made this wise observation:\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\nEven experienced programmers find themselves bashing their heads against seemingly intractable errors. If you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, e-mail me, etc.\nLeaRning is Social The students who have a bad time in my workshops and courses are the ones who don’t work with each other to learn. We are a learning community, and we should help each other to learn.\nIf you understand something and someone is struggling with it, try and help them. If you are struggling, take a breath, and try to pinpoint what you are struggling with.\nOur goal is to be better programmers each day, not to be the perfect programmer. There’s no such thing as a perfect programmer. I’ve been learning new things almost every day.\nCopyright Information Every reasonable effort has been made to protect the copyright requirements of materials used in this course. Class participants are warned not to copy, audio, or videotape in violation of copyright laws.\nJournal articles will be kept on reserve at the library or online for student access. Copyright law does allow for making one personal copy of each article from the original article. This limit also applies to electronic sources.\nTo comply with the fair use fair use doctrine of the US copyright law, Sakai course sites close three weeks after grades are posted with the Registrar. Please be sure to download all course material you wish to keep before this time as you will have no further access to your courses.\nSchool of Public Health Handbook All students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook: https://ohsu-psu-sph.org/graduate-students-policies-and-procedures-2/\nSyllabus Changes and Retention This syllabus is not to be considered a contract between the student and the School of Public Health. It is recognized that changes may be made as the need arises. Students are responsible for keeping a copy of the course syllabus for their records.\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the Course Syllabi Policy, 02-50-050.\nSyllabus Statement Regarding Disability Services OHSU is committed to providing equal access to qualified students who experience a disability in compliance with Section 504 of the Rehabilitation Act of 1973, the Americans with Disabilities Act (ADA) of 1990, and the ADA Amendments Act (ADA-AA) of 2008. If you have a disability or think you may have a disability (physical, sensory, chronic health, psychological or learning) please contact the Office for Student Access at (503) 494-0082 or studentaccess@ohsu.edu to discuss eligibility for academic accommodations. Information is also available at www.ohsu.edu/student-access. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible. All information regarding a student’s disability is kept in accordance with relevant state and federal laws.\nPlease see Student Access \u0026amp; Accomodations section for more details on the Sakai version of this Syllabus.\nCommitment of Equity and Inclusion The School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reached at 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’s Response to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503- 494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919.\nAcademic Honesty Course participants are expected to maintain academic honesty in their course work. Participants should refrain from seeking past published solutions to any assignments. Literature and resources (including Internet resources) employed in fulfilling assignments must be cited. See http://www.ohsu.edu/xd/education/library/research-assistance/plagiarism.cfm?WT_rank=1# for information on code of conduct for OHSU and\nhttp://www.ohsu.edu/xd/education/teaching-and-learning-center/for-students/index.cfm for more information on citing sources and recognizing plagiarism.\nIn an effort to uphold the principles and practice of academic honesty, faculty members at OHSU may use originality checking systems such as Turnitin to compare a student’s submitted work against multiple sources.\nTo protect student privacy in this process, it will be necessary to remove all personal information, i.e. student name, email address, student u-number, or any other personal information, from documents BEFORE submission.\nUse of Sakai This course will have an online component, which can be accessed through Sakai, OHSU’s online course management system. For any technical questions or if you need help logging in, please contact the Sakai Help Desk.\nHours: Sakai Help Desk is available Mon – Fri, 8 am – 9 pm and weekends 12 pm – 5 pm, Pacific Time.\nContact Information:\n(Toll-free) 877-972-5249\n(Web) http://atech.ohsu.edu/help\n(Email) sakai@ohsu.edu\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673221560,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"https://sph-r-programming-2023.netlify.app/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Course Description Credit Hours Learning Objectives Course Website Office Hours Prerequisites or Concurrent Enrollment Requirements Faculty Information Instructor Teaching Assistant Attendance Requirements Homework Function of the week Midterm and Final Grading Policy Late Policy Code of Conduct Required Texts or Readings Words of Encouragement LeaRning is Social Copyright Information School of Public Health Handbook Syllabus Changes and Retention Syllabus Statement Regarding Disability Services Commitment of Equity and Inclusion Academic Honesty Use of Sakai Instructor Dr.","tags":null,"title":"Syllabus","type":"page"},{"authors":null,"categories":null,"content":" R Project files Before each class, I will load an R project on github, and provide the download link here. Unzip this folder and open in Rstudio by double clicking on the .Rproj file. This folder will have the files for this part and the assignment.\nClass Video The video will be uploaded after class.\nView last year’s class and materials here.\nSlides To be posted.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture. All responses will be anonymous.\nClearest Point: What was the most clear part of the lecture? Muddiest Point: What was the most unclear part of the lecture to you? Anything Else: Is there something you’d like me to know? https://forms.gle/4tVx1mL7SzQx7MCu5\nMuddiest Points/Clearest Points I will add the muddiest/clearest points from the survey after the first class.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672873994,"objectID":"8b2aba8869e8a2568f8b5c8687d037d9","permalink":"https://sph-r-programming-2023.netlify.app/class/00-class-template/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/00-class-template/","section":"class","summary":"R Project files Before each class, I will load an R project on github, and provide the download link here. Unzip this folder and open in Rstudio by double clicking on the .Rproj file. This folder will have the files for this part and the assignment.\nClass Video The video will be uploaded after class.\nView last year’s class and materials here.\nSlides To be posted.\nPost-Class Please fill out the following survey and we will discuss the results during the next lecture.","tags":null,"title":"tmp","type":"class"}]